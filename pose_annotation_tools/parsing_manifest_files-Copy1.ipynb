{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist, euclidean\n",
    "import pickle\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'D:\\\\Dropbox\\\\research\\\\#MARS_AND_BENTO\\\\AMT_reannotation\\\\datasets\\\\white_100\\\\'\n",
    "manifest_name = 'white_mouse_100_output'\n",
    "nWorkers = 6\n",
    "config = 'project_config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'annot_config.yml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-5851bbbefa97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mcfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'annot_config.yml'"
     ]
    }
   ],
   "source": [
    "# first read the config and the output manifest:\n",
    "fid = data_dir + manifest_name + ('.manifest' if not manifest_name.endswith('.manifest') else '')\n",
    "\n",
    "data = []\n",
    "for line in open(fid,'r'):\n",
    "    data.append(json.loads(line))\n",
    "\n",
    "with open(config) as f:\n",
    "    cfg = yaml.load(f)\n",
    "\n",
    "keypoints = cfg['keypoints']\n",
    "animal_names = cfg['animal_names'] if cfg['animal_names'] else animal\n",
    "species = cfg['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_names=['mouse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "nWorkers=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 685.5,  543. ],\n",
       "       [ 755.5,  419. ],\n",
       "       [ 753.5,  434. ],\n",
       "       [ 792.5,  409. ],\n",
       "       [ 920. ,  512.5],\n",
       "       [ 925. ,  510. ],\n",
       "       [1007. ,  490.5]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(rawPts['mouse'],axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next we unpack the raw data from all individual annotators\n",
    "\n",
    "nKpts   = len(keypoints)\n",
    "\n",
    "for f, sample in enumerate(data):\n",
    "    if ('annotatedResult' in sample.keys()): #check if this frame has at least one set of annotations\n",
    "\n",
    "        rawPts = {n:np.zeros((nKpts, 2, nWorkers)) for n in animal_names}\n",
    "        for w,worker in enumerate(sample['annotatedResult']['annotationsFromAllWorkers']):\n",
    "            workerCount[f] = workerCount[f] + 1\n",
    "\n",
    "            # the json of annotations from each worker is stored as a string for security reasons.\n",
    "            # we'll use eval to convert it into a dict:\n",
    "            annot = eval(worker['annotationData']['content'])\n",
    "\n",
    "            # now we can unpack this worker's annotations for each keypoint:\n",
    "            for pt in annot['annotatedResult']['keypoints']:\n",
    "                animal = next((n for n in animal_names if n in pt['label']),cfg['species'])\n",
    "                part = keypoints.index(pt['label'].replace(animal, '').replace(species, '').strip())\n",
    "\n",
    "                rawPts[animal][part,0,w] = pt['x'] #/im.shape[1]\n",
    "                rawPts[animal][part,1,w] = pt['y'] #/im.shape[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-99854fd6e1b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;31m# now we can unpack this worker's annotations for each keypoint:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mpt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mannot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'annotatedResult'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'keypoints'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0manimal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manimal_names\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'species'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m                 \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeypoint_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manimal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspecies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "# next we unpack the raw data from all individual annotators\n",
    "\n",
    "nSamp   = len(data)\n",
    "nKpts   = len(keypoints)\n",
    "\n",
    "# for each image: nKpts keypoints, 2 dimensions, nWorkers workers per keypoint\n",
    "rawPts={}\n",
    "\n",
    "rawPts = {n:np.zeros((nSamp,nKpts,2,nWorkers)) for n in animal_names}\n",
    "\n",
    "images = ['']*nSamp        # track paths to labeled images\n",
    "hits = [False]*nSamp       # track which images have annotations\n",
    "workerCount = [0]*nSamp    # track the number of workers who labeled each image\n",
    "\n",
    "sourceStr = os.path.dirname(data[0]['source-ref']) # name of the bucket images are in on AWS\n",
    "\n",
    "for f,frame in enumerate(data):\n",
    "    if ('annotatedResult' in frame.keys()): #check if this frame has at least one set of annotations\n",
    "        hits[f] = True\n",
    "\n",
    "        images[f] = frame['source-ref']\n",
    "\n",
    "        for w,worker in enumerate(frame['annotatedResult']['annotationsFromAllWorkers']):\n",
    "            workerCount[f] = workerCount[f] + 1\n",
    "\n",
    "            # the json of annotations from each worker is stored as a string for security reasons.\n",
    "            # we'll use eval to convert it into a dict:\n",
    "            annot = eval(worker['annotationData']['content'])\n",
    "\n",
    "            # now we can unpack this worker's annotations for each keypoint:\n",
    "            for pt in annot['annotatedResult']['keypoints']:\n",
    "                animal = next((n for n in animal_names if n in pt['label']),'animal')\n",
    "                idx = keypoints.index(pt['label'].replace(animal,'').replace(species,'').strip())\n",
    "                \n",
    "                rawPts[animal][f,idx,0,w] = pt['x']\n",
    "                rawPts[animal][f,idx,1,w] = pt['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 704.  682.  684.  687.  693.  683.]\n",
      "  [ 534.  547.  543.  543.  541.  544.]]\n",
      "\n",
      " [[ 786.  797.  725.  712.  782.  729.]\n",
      "  [ 452.  435.  422.  399.  444.  416.]]\n",
      "\n",
      " [[ 723.  715.  784.  804.  722.  815.]\n",
      "  [ 435.  415.  451.  408.  433.  426.]]\n",
      "\n",
      " [[ 806.  792.  803.  780.  793.  782.]\n",
      "  [ 437.  418.  410.  408.  405.  408.]]\n",
      "\n",
      " [[ 871.  908.  952.  932.  937.  874.]\n",
      "  [ 521.  473.  543.  529.  504.  483.]]\n",
      "\n",
      " [[ 920.  930.  910.  937.  849.  957.]\n",
      "  [ 444.  542.  511.  580.  507.  509.]]\n",
      "\n",
      " [[ 977.  988.  999. 1016. 1023. 1015.]\n",
      "  [ 496.  485.  483.  522.  461.  534.]]]\n",
      "[[[ 704.  682.  684.  687.  693.  683.]\n",
      "  [ 534.  547.  543.  543.  541.  544.]]\n",
      "\n",
      " [[ 786.  797.  725.  804.  782.  729.]\n",
      "  [ 452.  435.  422.  408.  444.  416.]]\n",
      "\n",
      " [[ 723.  715.  784.  712.  722.  815.]\n",
      "  [ 435.  415.  451.  399.  433.  426.]]\n",
      "\n",
      " [[ 806.  792.  803.  780.  793.  782.]\n",
      "  [ 437.  418.  410.  408.  405.  408.]]\n",
      "\n",
      " [[ 871.  908.  952.  932.  937.  874.]\n",
      "  [ 521.  473.  543.  529.  504.  483.]]\n",
      "\n",
      " [[ 920.  930.  910.  937.  849.  957.]\n",
      "  [ 444.  542.  511.  580.  507.  509.]]\n",
      "\n",
      " [[ 977.  988.  999. 1016. 1023. 1015.]\n",
      "  [ 496.  485.  483.  522.  461.  534.]]]\n"
     ]
    }
   ],
   "source": [
    "print(frame)\n",
    "print(frame2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's get our ground-truth keypoints by taking the median across annotators.\n",
    "\n",
    "gtPts  = {n:[] for n in animal_names}\n",
    "allPts = {n:[] for n in animal_names}\n",
    "\n",
    "for animal in animal_names:\n",
    "    #first we'll take medians of the raw keypoints:\n",
    "    gtPts[animal] = np.zeros((nSamp,nKpts,2))\n",
    "    f=0\n",
    "    rame = rawPts[animal][0]\n",
    "#     for f,frame in enumerate(rawPts[animal]):\n",
    "    meds = np.median(np.squeeze(frame.T),axis=0)\n",
    "\n",
    "    gtPts[animal][f,:,:] = meds.T\n",
    "    frame2 = np.copy(frame)\n",
    "    i1 = 1\n",
    "    i2 = 2\n",
    "    frame[[i1, i2],:,3] = frame[[i2, i1],:,3]\n",
    "\n",
    "    for w,worker in enumerate(frame.swapaxes(0,2).swapaxes(1,2)):\n",
    "            d1 = cdist(worker[[i1,i2],:],[meds[:,i1]])\n",
    "            d2 = cdist(worker[[i1,i2],:],[meds[:,i2]])\n",
    "            if (d1[0]>d2[1]) and (d2[1]>d1[0]):\n",
    "                frame2[[i1, i2],:,w] = frame[[i2, i1],:,w]\n",
    "\n",
    "    # then we'll adjust L/R assignments to try to find better median estimates. Iterating\n",
    "    # seems to help settle on better final keypoints if the initial guesses were especially bad.\n",
    "#     for rep in range(1):\n",
    "#         # for ears and hips we should check for + correct Left/Right swaps, a common annotator mistake:\n",
    "#         allPts[animal] = np.copy(rawPts[animal])\n",
    "        \n",
    "#         for fr,(gt,frame) in enumerate(zip(gtPts[animal],rawPts[animal])):\n",
    "#             for w,worker in enumerate(frame.swapaxes(0,2).swapaxes(1,2)):\n",
    "                \n",
    "#                 dEar1 = cdist(worker[1:3,:],[gt[1]])\n",
    "#                 dEar2 = cdist(worker[1:3,:],[gt[2]])\n",
    "#                 if (dEar1[0]>dEar1[1]) and (dEar2[1]>dEar1[0]):\n",
    "#                     allPts[animal][fr,1,:,w] = rawPts[animal][fr,2,:,w]\n",
    "#                     allPts[animal][fr,2,:,w] = rawPts[animal][fr,1,:,w]\n",
    "                \n",
    "#                 dHip1 = cdist(worker[4:6,:],[gt[4]])\n",
    "#                 dHip2 = cdist(worker[4:6,:],[gt[5]])\n",
    "#                 if (dHip1[0]>dHip1[1]) and (dHip2[1]>dHip2[0]):\n",
    "#                     allPts[animal][fr,4,:,w] = rawPts[animal][fr,5,:,w]\n",
    "#                     allPts[animal][fr,5,:,w] = rawPts[animal][fr,4,:,w]\n",
    "\n",
    "#         # then re-compute the medians:\n",
    "#         gtPts[animal] = np.zeros((nSamp,nKpts,2))\n",
    "#         for f,frame in enumerate(allPts[animal]):\n",
    "#             for p,pt in enumerate(frame):\n",
    "#                 gtPts[animal][f,p,:] = geometric_median(np.squeeze(pt.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at a couple example images to see how our annotators did.\n",
    "# (note, this also saves the figure as a pdf in lbl_bucket):\n",
    "\n",
    "# each body part gets an assigned color; each annotator gets an assigned marker.\n",
    "colors  = 'rgbcmyw'\n",
    "markers = 'v+xosd'\n",
    "\n",
    "fig,ax = plt.subplots(5,2,figsize=(16, 30))\n",
    "for fr in range(0,10):\n",
    "    im = mpimg.imread(images[fr])\n",
    "    ax[int(fr/2),(fr+1)%2].imshow(im);\n",
    "    \n",
    "    # plot the labels from each individual worker:\n",
    "    for mouse,mouseColor in zip(['white','black'],['w','k']):\n",
    "        for p,pt in enumerate(np.squeeze(allPts[mouse][fr,...])):\n",
    "            for w in range(nWorkers):\n",
    "                ax[int(fr/2),(fr+1)%2].plot(pt[0,w], pt[1,w],colors[p] + markers[w], markersize=2,markeredgecolor=mouseColor)\n",
    "\n",
    "        # plot the \"ground truth\" labels:\n",
    "        ax[int(fr/2),(fr+1)%2].plot(gtPts[mouse][fr,:,0], gtPts[mouse][fr,:,1],'k.', markersize=4)\n",
    "\n",
    "fig.savefig('s3://{}/sample_annotations.pdf'.format(lbl_bucket), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we'd like to quantify annotator variability. For some reason, this seems to be a good predictor\n",
    "# of how well our pose estimator is going to do once trained.\n",
    "\n",
    "pixels_per_cm = 37.795\n",
    "\n",
    "fig,ax = plt.subplots(2,4,figsize=(16, 8))\n",
    "dashes = {'white':'dotted', 'black':'dashed', 'both':'solid'}\n",
    "colors = 'rbg'\n",
    "\n",
    "for mouse in ['white','black','both']:\n",
    "    if mouse != 'both':\n",
    "        dMean = np.zeros((nKpts,nSamp)) # average worker-gt distance\n",
    "        dMin  = np.zeros((nKpts,nSamp)) # performance of best worker on a given frame\n",
    "        dMax  = np.zeros((nKpts,nSamp)) # performance of worst worker on a given frame\n",
    "        for fr,(gt,est) in enumerate(zip(gtPts[mouse],allPts[mouse])):\n",
    "            for pt,(gtPt,estPts) in enumerate(zip(gt,est)):\n",
    "                D = cdist(estPts.T, [gtPt]) / pixels_per_cm\n",
    "                dMean[pt,fr] = np.mean(D)\n",
    "                dMin[pt,fr]  = min(D)\n",
    "                dMax[pt,fr]  = max(D)\n",
    "    else:\n",
    "        dMean = np.zeros((nKpts,nSamp*2))\n",
    "        dMin  = np.zeros((nKpts,nSamp*2))\n",
    "        dMax  = np.zeros((nKpts,nSamp*2))\n",
    "        for fr,(gt,est) in enumerate(zip(np.concatenate((gtPts['white'],gtPts['black'])), \\\n",
    "                                        np.concatenate((allPts['white'],allPts['black'])))):\n",
    "            for pt,(gtPt,estPts) in enumerate(zip(gt,est)):\n",
    "                D = cdist(estPts.T, [gtPt]) / pixels_per_cm\n",
    "                dMean[pt,fr] = np.mean(D)\n",
    "                dMin[pt,fr]  = min(D)\n",
    "                dMax[pt,fr]  = max(D)\n",
    "\n",
    "    showMax = 3\n",
    "    bins = 10000\n",
    "    binrange = [-1/bins, 500]\n",
    "\n",
    "    for c,use in enumerate([dMin,dMean,dMax]):\n",
    "        for p,pt in enumerate(use):\n",
    "            counts,usedbins = np.histogram(pt,bins,range=binrange,density=True)\n",
    "            ax[int(p/4),p%4].plot(usedbins[1:], counts.cumsum()/bins*binrange[1], colors[c], ls=dashes[mouse])\n",
    "            ax[int(p/4),p%4].set_title(order[p])\n",
    "            ax[int(p/4),p%4].set_xlim([0,showMax])\n",
    "            ax[int(p/4),p%4].plot([1,1],[0,1],'k--')\n",
    "            ax[int(p/4),p%4].plot([0,showMax],[.8,.8],'k--')\n",
    "\n",
    "        counts,usedbins = np.histogram(use.ravel(),bins,range=binrange,density=True)\n",
    "        ax[1,3].plot(usedbins[1:], counts.cumsum()/bins*binrange[1], colors[c], ls=dashes[mouse])\n",
    "        ax[1,3].plot([1,1],[0,1],'k--')\n",
    "        ax[1,3].plot([0,showMax],[.8,.8],'k--')\n",
    "        ax[1,3].set_title('all');\n",
    "        ax[1,3].set_xlim([0,showMax])\n",
    "\n",
    "fig.savefig('s3://{}/performance.pdf'.format(lbl_bucket), bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
