{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DSCk8EBgul9k"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist, euclidean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qe3l6l-gvaHX"
   },
   "source": [
    "# Functions and Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2dlwLYJExEw"
   },
   "outputs": [],
   "source": [
    "# Input manifest file.\n",
    "manifest_file_name = 'output.manifest'\n",
    "\n",
    "# Path to the images used to obtain the manifest file.\n",
    "im_path = '/content/image_path/' \n",
    "\n",
    "# Path to save the intermediate dictionary file.\n",
    "dictionary_file_path = '/content/saved_dictionary'\n",
    "\n",
    "# Path to save the pose estimation tfrecord.\n",
    "pose_estimation_tfrecord_output_name = '/content/pose_estimation_tfrecord'\n",
    "\n",
    "# Path to save the bounding box detection tfrecord (black mouse).\n",
    "detection_black_tfrecord_output_name = '/content/detection_black_tfrecord'\n",
    "\n",
    "# Path to save the bounding box detection tfrecord (white mouse).\n",
    "detection_white_tfrecord_output_name = '/content/detection_white_tfrecord'\n",
    "\n",
    "nSamp   = len(data)\n",
    "nKpts   = 7\n",
    "nWorkers = 5\n",
    "order   = ['nose','right ear','left ear','top of neck','right rear knee','left rear knee','base of tail']\n",
    "\n",
    "# name for the dict containing annotation data- this was set in run_labeling_job\n",
    "keyName = 'annotatedResult' \n",
    "\n",
    "# Whether we want to split the data from the manifest file as train, val, test\n",
    "# Put False here if the dataplit is already done and we just want to save a single tfrecord\n",
    "split_train_val_test = True \n",
    "\n",
    "# Output name of the tfrecords\n",
    "output_tfrecord_name_detection = \"tfrecord_detection\"\n",
    "output_tfrecord_name_pose = \"tfrecord_pose\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UtB3YhPruQ5L"
   },
   "outputs": [],
   "source": [
    "# Read manifest file.\n",
    "fid = open(manifest_file_name, 'r')\n",
    "data = []\n",
    "string = ''\n",
    "for line in fid:\n",
    "    data.append(json.loads(line))\n",
    "    string = string + line + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ioAVGO14uZ3y"
   },
   "outputs": [],
   "source": [
    "# we're going to set our ground-truth points as the geometric median of all the annotators.\n",
    "# This algorithm for the geometric median comes from Vardi and Zhang 1999, as implemented by orlp on Stack Overflow\n",
    "# (https://stackoverflow.com/questions/30299267/geometric-median-of-multidimensional-points)\n",
    "\n",
    "def geometric_median(X, eps=1e-1):\n",
    "    y = np.mean(X, 0)\n",
    "    \n",
    "    count=0\n",
    "    while True:\n",
    "        count=count+1\n",
    "        D = cdist(X, [y])\n",
    "        nonzeros = (D != 0)[:, 0]\n",
    "\n",
    "        Dinv = 1 / D[nonzeros]\n",
    "        Dinvs = np.sum(Dinv)\n",
    "        W = Dinv / Dinvs\n",
    "        T = np.sum(W * X[nonzeros], 0)\n",
    "\n",
    "        num_zeros = len(X) - np.sum(nonzeros)\n",
    "        if num_zeros == 0:\n",
    "            y1 = T\n",
    "        elif num_zeros == len(X):\n",
    "            return y\n",
    "        else:\n",
    "            R = (T - y) * Dinvs\n",
    "            r = np.linalg.norm(R)\n",
    "            rinv = 0 if r == 0 else num_zeros/r\n",
    "            y1 = max(0, 1-rinv)*T + min(1, rinv)*y\n",
    "\n",
    "        if euclidean(y, y1) < eps:\n",
    "            return y1\n",
    "        \n",
    "        if count>10:\n",
    "            return y1\n",
    "\n",
    "        y = y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQXiP-lyzatS"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create the tfrecord files for a dataset.\n",
    "A lot of this code comes from the tensorflow inception example, so here is their license:\n",
    "# Copyright 2016 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "###added  path to tfrecords features\n",
    "\"\"\"\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "from queue import Queue\n",
    "import sys\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import threading\n",
    "import random\n",
    "import pdb\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Wrapper for inserting int64 features into Example proto.\"\"\"\n",
    "  if not isinstance(value, list):\n",
    "    value = [value]\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Wrapper for inserting float features into Example proto.\"\"\"\n",
    "  if not isinstance(value, list):\n",
    "    value = [value]\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Wrapper for inserting bytes features into Example proto.\"\"\"\n",
    "  if isinstance(value, str):\n",
    "    value = value.encode('utf-8')\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _convert_to_example(image_example, image_buffer, height, width):\n",
    "  \"\"\"Build an Example proto for an example.\n",
    "  Args:\n",
    "    image_example: dict, an image example\n",
    "    image_buffer: string, JPEG encoding of RGB image\n",
    "    height: integer, image height in pixels\n",
    "    width: integer, image width in pixels\n",
    "  Returns:\n",
    "    Example proto\n",
    "  \"\"\"\n",
    "  \n",
    "  # Required\n",
    "  filename = str(image_example['filename'])\n",
    "  id = str(image_example['id'])\n",
    "  \n",
    "  # Class label for the whole image\n",
    "  image_class = image_example.get('class', {})\n",
    "  class_label = image_class.get('label', 0)\n",
    "  class_text = str(image_class.get('text', b''))\n",
    "  \n",
    "  # Bounding Boxes\n",
    "  image_objects = image_example.get('object', {})\n",
    "  image_bboxes = image_objects.get('bbox', {})\n",
    "  xmin = image_bboxes.get('xmin', [])\n",
    "  xmax = image_bboxes.get('xmax', [])\n",
    "  ymin = image_bboxes.get('ymin', [])\n",
    "  ymax = image_bboxes.get('ymax', [])\n",
    "  bbox_labels = image_bboxes.get('label', [])\n",
    "  bbox_scores = image_bboxes.get('score', [])\n",
    "  bbox_count = image_bboxes.get('count', 0)\n",
    "  \n",
    "  # Parts\n",
    "  image_parts = image_objects.get('parts', {})\n",
    "  parts_x = image_parts.get('x', [])\n",
    "  parts_y = image_parts.get('y', [])\n",
    "  parts_v = image_parts.get('v', [])\n",
    "  \n",
    "  # Areas\n",
    "  object_areas = image_objects.get('area', [])\n",
    "  \n",
    "  # Ids\n",
    "  object_ids = image_objects.get('id', [])\n",
    "  \n",
    "  colorspace = b'RGB'\n",
    "  channels = 3\n",
    "  image_format = b'JPEG'\n",
    "\n",
    "  example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': _int64_feature(height),\n",
    "      'image/width': _int64_feature(width),\n",
    "      'image/colorspace': _bytes_feature(colorspace),\n",
    "      'image/channels': _int64_feature(channels),\n",
    "      'image/class/label': _int64_feature(class_label),\n",
    "      'image/class/text': _bytes_feature(class_text),\n",
    "      'image/object/bbox/xmin': _float_feature(xmin),\n",
    "      'image/object/bbox/xmax': _float_feature(xmax),\n",
    "      'image/object/bbox/ymin': _float_feature(ymin),\n",
    "      'image/object/bbox/ymax': _float_feature(ymax),\n",
    "      'image/object/bbox/label': _int64_feature(bbox_labels),\n",
    "      'image/object/bbox/count' : _int64_feature(bbox_count),\n",
    "      'image/object/bbox/score' : _float_feature(bbox_scores),\n",
    "      'image/object/parts/x' : _float_feature(parts_x),\n",
    "      'image/object/parts/y' : _float_feature(parts_y),\n",
    "      'image/object/parts/v' : _int64_feature(parts_v),\n",
    "      'image/object/parts/count' : _int64_feature(len(parts_v)),\n",
    "      'image/object/area' : _float_feature(object_areas),\n",
    "      'image/object/id' : _int64_feature(object_ids),\n",
    "      'image/format': _bytes_feature(image_format),\n",
    "      'image/filename': _bytes_feature(os.path.basename(filename)),\n",
    "      'image/path': _bytes_feature(os.path.dirname(filename)),\n",
    "      'image/id': _bytes_feature(str(id)),\n",
    "      'image/encoded': _bytes_feature(image_buffer)}))\n",
    "  return example\n",
    "\n",
    "\n",
    "class ImageCoder(object):\n",
    "  \"\"\"Helper class that provides TensorFlow image coding utilities.\"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    # Create a single Session to run all image coding calls.\n",
    "    self._sess = tf.Session()\n",
    "\n",
    "    # Initializes function that converts PNG to JPEG data.\n",
    "    self._png_data = tf.placeholder(dtype=tf.string)\n",
    "    image = tf.image.decode_png(self._png_data, channels=3)\n",
    "    self._png_to_jpeg = tf.image.encode_jpeg(image, format='rgb', quality=100)\n",
    "\n",
    "    # Initializes function that decodes RGB JPEG data.\n",
    "    self._decode_jpeg_data = tf.placeholder(dtype=tf.string)\n",
    "    self._decode_jpeg = tf.image.decode_jpeg(self._decode_jpeg_data, channels=3)\n",
    "\n",
    "  def png_to_jpeg(self, image_data):\n",
    "    return self._sess.run(self._png_to_jpeg,\n",
    "                          feed_dict={self._png_data: image_data})\n",
    "\n",
    "  def decode_jpeg(self, image_data):\n",
    "    image = self._sess.run(self._decode_jpeg,\n",
    "                           feed_dict={self._decode_jpeg_data: image_data})\n",
    "    assert len(image.shape) == 3\n",
    "    assert image.shape[2] == 3\n",
    "    return image\n",
    "\n",
    "def _is_png(filename):\n",
    "  \"\"\"Determine if a file contains a PNG format image.\n",
    "  Args:\n",
    "    filename: string, path of the image file.\n",
    "  Returns:\n",
    "    boolean indicating if the image is a PNG.\n",
    "  \"\"\"\n",
    "  filepath, file_extension = os.path.splitext(filename)\n",
    "  if file_extension == '.png':\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def _process_image(filename, coder):\n",
    "  \"\"\"Process a single image file.\n",
    "  Args:\n",
    "    filename: string, path to an image file e.g., '/path/to/example.JPG'.\n",
    "    coder: instance of ImageCoder to provide TensorFlow image coding utils.\n",
    "  Returns:\n",
    "    image_buffer: string, JPEG encoding of RGB image.\n",
    "    height: integer, image height in pixels.\n",
    "    width: integer, image width in pixels.\n",
    "  \"\"\"\n",
    "  # Read the image file.\n",
    "  image_data = tf.gfile.FastGFile(filename, 'rb').read()\n",
    "\n",
    "  # Clean the dirty data.\n",
    "  if _is_png(filename):\n",
    "    # 1 image is a PNG.\n",
    "    #print('Converting PNG to JPEG for %s' % filename)\n",
    "    image_data = coder.png_to_jpeg(image_data)\n",
    "\n",
    "  # Decode the RGB JPEG.\n",
    "  image = coder.decode_jpeg(image_data)\n",
    "  # Check that image converted to RGB\n",
    "  assert len(image.shape) == 3\n",
    "  height = image.shape[0]\n",
    "  width = image.shape[1]\n",
    "  assert image.shape[2] == 3\n",
    "\n",
    "  return image_data, height, width\n",
    "\n",
    "\n",
    "def _process_image_files_batch(coder, thread_index, ranges, name, output_directory, dataset, num_shards, error_queue):\n",
    "  \"\"\"Processes and saves list of images as TFRecord in 1 thread.\n",
    "  Args:\n",
    "    coder: instance of ImageCoder to provide TensorFlow image coding utils.\n",
    "    thread_index: integer, unique batch to run index is within [0, len(ranges)).\n",
    "    ranges: list of pairs of integers specifying ranges of each batches to\n",
    "      analyze in parallel.\n",
    "    name: string, unique identifier specifying the data set (e.g. `train` or `test`)\n",
    "    output_directory: string, file path to store the tfrecord files.\n",
    "    dataset: list, a list of image example dicts\n",
    "    num_shards: integer number of shards for this data set.\n",
    "    error_queue: Queue, a queue to place image examples that failed.\n",
    "  \"\"\"\n",
    "  # Each thread produces N shards where N = int(num_shards / num_threads).\n",
    "  # For instance, if num_shards = 128, and the num_threads = 2, then the first\n",
    "  # thread would produce shards [0, 64).\n",
    "  num_threads = len(ranges)\n",
    "  assert not num_shards % num_threads\n",
    "  num_shards_per_batch = int(num_shards / num_threads)\n",
    "\n",
    "  shard_ranges = np.linspace(ranges[thread_index][0],\n",
    "                             ranges[thread_index][1],\n",
    "                             num_shards_per_batch + 1).astype(int)\n",
    "  num_files_in_thread = ranges[thread_index][1] - ranges[thread_index][0]\n",
    "\n",
    "  counter = 0\n",
    "  error_counter = 0\n",
    "  for s in range(num_shards_per_batch):\n",
    "    # Generate a sharded version of the file name, e.g. 'train-00002-of-00010'\n",
    "    shard = thread_index * num_shards_per_batch + s\n",
    "    output_filename = '%s-%.5d-of-%.5d' % (name, shard, num_shards)\n",
    "    output_file = os.path.join(output_directory, output_filename)\n",
    "    writer = tf.python_io.TFRecordWriter(output_file)\n",
    "\n",
    "    shard_counter = 0\n",
    "    files_in_shard = np.arange(shard_ranges[s], shard_ranges[s + 1], dtype=int)\n",
    "    for i in files_in_shard:\n",
    "      \n",
    "      image_example = dataset[i]\n",
    "      \n",
    "      filename = str(image_example['filename'])\n",
    "\n",
    "      try:\n",
    "        image_buffer, height, width = _process_image(filename, coder)\n",
    "\n",
    "        # if len(image_buffer) == 0:\n",
    "        #   print(image_buffer, height, width)\n",
    "        \n",
    "        example = _convert_to_example(image_example, image_buffer, height, width)\n",
    "        writer.write(example.SerializeToString())\n",
    "        shard_counter += 1\n",
    "        counter += 1\n",
    "      except Exception as e:\n",
    "        raise\n",
    "        error_counter += 1\n",
    "        error_queue.put(image_example)\n",
    "\n",
    "      if not counter % 1000:\n",
    "        print('%s [thread %d]: Processed %d of %d images in thread batch, with %d errors.' %\n",
    "              (datetime.now(), thread_index, counter, num_files_in_thread, error_counter))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    print('%s [thread %d]: Wrote %d images to %s, with %d errors.' %\n",
    "          (datetime.now(), thread_index, shard_counter, output_file, error_counter))\n",
    "    sys.stdout.flush()\n",
    "    shard_counter = 0\n",
    "    \n",
    "  print('%s [thread %d]: Wrote %d images to %d shards, with %d errors.' %\n",
    "        (datetime.now(), thread_index, counter, num_files_in_thread, error_counter))\n",
    "  sys.stdout.flush()\n",
    "  \n",
    "\n",
    "def create(dataset, dataset_name, output_directory, num_shards, num_threads, shuffle=True):\n",
    "  \"\"\"Create the tfrecord files to be used to train or test a model.\n",
    "  \n",
    "  Args:\n",
    "    dataset : [{\n",
    "      \"filename\" : <REQUIRED: path to the image file>, \n",
    "      \"id\" : <REQUIRED: id of the image>,\n",
    "      \"class\" : {\n",
    "        \"label\" : <[0, num_classes)>,\n",
    "        \"text\" : <text description of class>\n",
    "      },\n",
    "      \"object\" : {\n",
    "        \"bbox\" : {\n",
    "          \"xmin\" : [],\n",
    "          \"xmax\" : [],\n",
    "          \"ymin\" : [],\n",
    "          \"ymax\" : [],\n",
    "          \"label\" : []\n",
    "        }\n",
    "      }\n",
    "    }]\n",
    "    \n",
    "    dataset_name: a name for the dataset\n",
    "    \n",
    "    output_directory: path to a directory to write the tfrecord files\n",
    "    \n",
    "    num_shards: the number of tfrecord files to create\n",
    "    \n",
    "    num_threads: the number of threads to use \n",
    "    shuffle : bool, should the image examples be shuffled or not prior to creating the tfrecords.\n",
    "  \n",
    "  Returns:\n",
    "    list : a list of image examples that failed to process.\n",
    "  \"\"\"\n",
    "  \n",
    "  # Images in the tfrecords set must be shuffled properly\n",
    "  if shuffle:\n",
    "    random.shuffle(dataset)\n",
    "\n",
    "  # Break all images into batches with a [ranges[i][0], ranges[i][1]].\n",
    "  spacing = np.linspace(0, len(dataset), num_threads + 1).astype(np.int)\n",
    "  ranges = []\n",
    "  threads = []\n",
    "  for i in range(len(spacing) - 1):\n",
    "    ranges.append([spacing[i], spacing[i+1]])\n",
    "\n",
    "  # Launch a thread for each batch.\n",
    "  print('Launching %d threads for spacings: %s' % (num_threads, ranges))\n",
    "  sys.stdout.flush()\n",
    "\n",
    "  # Create a mechanism for monitoring when all threads are finished.\n",
    "  coord = tf.train.Coordinator()\n",
    "\n",
    "  # Create a generic TensorFlow-based utility for converting all image codings.\n",
    "  coder = ImageCoder()\n",
    "  \n",
    "  # A Queue to hold the image examples that fail to process. \n",
    "  error_queue = Queue()  \n",
    "  \n",
    "  threads = []\n",
    "  for thread_index in range(len(ranges)):\n",
    "    args = (coder, thread_index, ranges, dataset_name, output_directory, dataset, num_shards, error_queue)\n",
    "    t = threading.Thread(target=_process_image_files_batch, args=args)\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "  # Wait for all the threads to terminate.\n",
    "  coord.join(threads)\n",
    "  print('%s: Finished writing all %d images in data set.' %\n",
    "        (datetime.now(), len(dataset)))\n",
    "  \n",
    "  # Collect the errors\n",
    "  errors = []\n",
    "  while not error_queue.empty():\n",
    "    errors.append(error_queue.get())\n",
    "  print ('%d examples failed.' % (len(errors),))\n",
    "  \n",
    "  return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OupOq0quvPKo"
   },
   "source": [
    "# Extract Annotations to an Intermediate Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZljyKcP4vSD6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "import scipy.io as sp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7tHiZRCwvhe"
   },
   "outputs": [],
   "source": [
    "D = []\n",
    "\n",
    "# for each frame in the csv file\n",
    "errors = []\n",
    "for f in range(nSamp):\n",
    "\n",
    "    print('Processing sample ' + str(f))\n",
    "\n",
    "    # Here we use the path to the image data to open the image.\n",
    "    im = Image.open(im_path + data[f]['source-ref'].split('/')[-1])\n",
    "    im = (np.asarray(im)).astype(float)\n",
    "\n",
    "    frame_dict = {\n",
    "        'frame_name': data[f]['source-ref'].split('/')[-1],\n",
    "        'height': im.shape[0],\n",
    "        'width': im.shape[1],\n",
    "        'frame_id':data[f]['source-ref'].split('/')[-1],\n",
    "        'ann_label':order,\n",
    "        'ann':[]\n",
    "    }\n",
    "\n",
    "    # extract info for each worker\n",
    "    N_workers = len(data[f]['annotatedResult']['annotationsFromAllWorkers'])\n",
    "    XB=[];YB=[];XW=[];YW=[];\n",
    "    for w in range(N_workers):\n",
    "      points_dict = eval(data[f]['annotatedResult']['annotationsFromAllWorkers'][w]['annotationData']['content'])\n",
    "\n",
    "      black_mouse_x = [0]*nKpts\n",
    "      black_mouse_y = [0]*nKpts\n",
    "      white_mouse_x = [0]*nKpts\n",
    "      white_mouse_y = [0]*nKpts    \n",
    "      for pt in points_dict['annotatedResult']['keypoints']:\n",
    "        mouse = 'black' if 'black' in pt['label'] else 'white'\n",
    "        idx = order.index(pt['label'].replace(mouse,'').replace('mouse','').strip())\n",
    "        \n",
    "        if mouse == 'black':\n",
    "          black_mouse_x[idx] = pt['x']/im.shape[1]\n",
    "          black_mouse_y[idx] = pt['y']/im.shape[0]\n",
    "        else:\n",
    "          white_mouse_x[idx] = pt['x']/im.shape[1]\n",
    "          white_mouse_y[idx] = pt['y']/im.shape[0]\n",
    "\n",
    "      XB.append(black_mouse_x)\n",
    "      YB.append(black_mouse_y)\n",
    "      XW.append(white_mouse_x)\n",
    "      YW.append(white_mouse_y)\n",
    "\n",
    "    # Compute some statistics for the tfrecord.\n",
    "    XB = np.array(XB);    YB = np.array(YB)\n",
    "    XW = np.array(XW);    YW = np.array(YW)\n",
    "\n",
    "    mXB = geometric_median(XB);    mYB = geometric_median(YB)\n",
    "    mXW = geometric_median(XW);    mYW = geometric_median(YW)\n",
    "\n",
    "    muXB = np.mean(XB,axis=0);     muYB = np.mean(YB, axis=0)\n",
    "    muXW = np.mean(XW, axis=0);    muYW = np.mean(YW, axis=0)\n",
    "\n",
    "    stdXB = np.std(YB, axis=0);  stdYB = np.std(YB, axis=0)\n",
    "    stdXW = np.std(XW, axis=0);  stdYW = np.std(YW, axis=0)\n",
    "\n",
    "    Bxmin = min(mXB);   Bxmax = max(mXB);\n",
    "    Bymin = min(mYB);   Bymax = max(mYB);\n",
    "    Wxmin = min(mXW);   Wxmax = max(mXW);\n",
    "    Wymin = min(mYW);   Wymax = max(mYW);\n",
    "\n",
    "    # Modify the box to be a bit larger than the keypoints.\n",
    "    def correct_box(xmin,xmax,ymin,ymax):\n",
    "        # Whether we use constant (vs width-based) stretch.\n",
    "        useConstant = 1\n",
    "\n",
    "        # Set the constant stretch amount.\n",
    "        stretch_const = 0.04\n",
    "\n",
    "        # Set the width stretch factor.\n",
    "        stretch_factor = 0.30\n",
    "\n",
    "        if useConstant:\n",
    "            stretch_constx = stretch_const\n",
    "            stretch_consty = stretch_const\n",
    "        else:\n",
    "            stretch_constx = (xmax - xmin) * stretch_factor  # of the width\n",
    "            stretch_consty = (ymax - ymin) * stretch_factor\n",
    "\n",
    "        # Calculate the amount to stretch the x by.\n",
    "        x_stretch = np.minimum(xmin, abs(1 - xmax))\n",
    "        x_stretch = np.minimum(x_stretch, stretch_constx)\n",
    "\n",
    "        # Calculate the amount to stretch the y by.\n",
    "        y_stretch = np.minimum(ymin, abs(1 - ymax))\n",
    "        y_stretch = np.minimum(y_stretch, stretch_consty)\n",
    "\n",
    "        # Adjust the bounding box accordingly.\n",
    "        xmin -= x_stretch\n",
    "        xmax += x_stretch\n",
    "        ymin -= y_stretch\n",
    "        ymax += y_stretch\n",
    "        return xmin,xmax,ymin,ymax\n",
    "\n",
    "    Bxmin,Bxmax,Bymin,Bymax = correct_box(Bxmin,Bxmax,Bymin,Bymax)\n",
    "    Wxmin,Wxmax,Wymin,Wymax = correct_box(Wxmin,Wxmax,Wymin,Wymax)\n",
    "\n",
    "    # area bboxes\n",
    "    Barea = abs(Bxmax-Bxmin)*abs(Bymax-Bymin)*im.shape[0]*im.shape[1]\n",
    "    Warea = abs(Wxmax-Wxmin)*abs(Wymax-Wymin)*im.shape[0]*im.shape[1]\n",
    "\n",
    "    # store info for Black and White mouse\n",
    "    frame_dict['ann_B']={'X':XB,\n",
    "                         'Y':YB,\n",
    "                         'bbox': np.array([Bxmin, Bxmax, Bymin, Bymax]),\n",
    "                         'med':np.array([mYB,mXB]),\n",
    "                         'mu':np.array([muYB,muXB]),\n",
    "                         'std':np.array([stdYB,stdXB]),\n",
    "                         'area':Barea,\n",
    "                         }\n",
    "    frame_dict['ann_W'] = {'X':XW,\n",
    "                           'Y':YW,\n",
    "                           'bbox': np.array([Wxmin, Wxmax, Wymin, Wymax]),\n",
    "                           'med': np.array([mYW, mXW]),\n",
    "                           'mu': np.array([muYW, muXW]),\n",
    "                           'std': np.array([stdYW,stdXW]),\n",
    "                           'area':Warea,\n",
    "                           }\n",
    "    D.append(frame_dict)\n",
    "\n",
    "# save info into pickle file\n",
    "with open(dictionary_file_path,'wb') as fp:\n",
    "    pickle.dump(D,fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_okn1KfuDnB7"
   },
   "source": [
    "# TFRecords for Training Pose Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dikCrjbgyJhH"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "import pdb\n",
    "import os\n",
    "import random\n",
    "\n",
    "#load extracted info from annotations\n",
    "open_file = dictionary_file_path\n",
    "with open(open_file,'rb') as fp:    D = pickle.load(fp)\n",
    "\n",
    "#prepare a dict with the info needed for the next step of preparing the tf records\n",
    "idg = 1\n",
    "v_info = []\n",
    "areas =[]\n",
    "for i in range(len(D)):\n",
    "    # image name and id\n",
    "    # bbox/label allows to separate between black or white mouse\n",
    "    # from the annotation 0 is the black mouse, 1 is the white mouse\n",
    "\n",
    "    B = D[i]['ann_B']['bbox']\n",
    "    W = D[i]['ann_W']['bbox']\n",
    "    Bp = D[i]['ann_B']['med']\n",
    "    Wp = D[i]['ann_W']['med']\n",
    "    i_frame = {'filename': im_path + D[i]['frame_name'],\n",
    "               'id': format(idg, '06d'),\n",
    "               \"class\": {\n",
    "                   \"label\": 0,\n",
    "                   \"text\": '',\n",
    "               },\n",
    "               'width': D[i]['width'],\n",
    "               'height': D[i]['height'],\n",
    "               'object': {\n",
    "                   'id':[0,1],\n",
    "                   'area':[ D[i]['ann_B']['area'], D[i]['ann_W']['area']],\n",
    "                   'bbox': {\n",
    "                       'xmin': [B[0],W[0]],\n",
    "                       'xmax': [B[1],W[1]],\n",
    "                       'ymin': [B[2],W[2]],\n",
    "                       'ymax': [B[3],W[3]],\n",
    "                       'label': [0,0],\n",
    "                       'count': 2,\n",
    "                       'score':[1,1]},\n",
    "                   'parts':{\n",
    "                        'x':Bp[1][:7].tolist() + Wp[1][:7].tolist(),\n",
    "                        'y':Bp[0][:7].tolist() + Wp[0][:7].tolist(),\n",
    "                        'v':[2]*(len(Bp[0][:7]) + len(Wp[0][:7])),\n",
    "                        'count': [len(Bp[0][:7]),len(Wp[0][:7])]\n",
    "                    }}}\n",
    "\n",
    "    v_info.append(i_frame)\n",
    "    idg += 1\n",
    "\n",
    "random.shuffle(v_info)\n",
    "\n",
    "#prepare tf records dataset\n",
    "# split train val test\n",
    "n = len(v_info)\n",
    "ntrain =int(math.floor(n * .85))\n",
    "nval = int(round(n * .05))\n",
    "ntest = int(round(n * .10))\n",
    "print(n, ntrain, nval, ntest)\n",
    "\n",
    "train = v_info[:ntrain]\n",
    "val = v_info[ntrain:ntrain + nval]\n",
    "test = v_info[ntrain + nval:]\n",
    "\n",
    "for i in range(len(v_info)):\n",
    "    if not v_info[i]['object']['area'][0]>0 or not v_info[i]['object']['area'][1]>0:\n",
    "        print(i)\n",
    "\n",
    "# create tf records\n",
    "create(\n",
    "    dataset=train,\n",
    "    dataset_name=\"train_dataset\",\n",
    "    output_directory=pose_estimation_tfrecord_output_name,\n",
    "    num_shards=10,\n",
    "    num_threads=5,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "create(\n",
    "    dataset=val,\n",
    "    dataset_name=\"val_dataset\",\n",
    "    output_directory=pose_estimation_tfrecord_output_name,\n",
    "    num_shards=1,\n",
    "    num_threads=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "create(\n",
    "    dataset=test,\n",
    "    dataset_name=\"test_dataset\",\n",
    "    output_directory=pose_estimation_tfrecord_output_name,\n",
    "    num_shards=1,\n",
    "    num_threads=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zd4OOsdNvTti"
   },
   "source": [
    "# TFRecords for Training Bounding Box Detector for Black and White Mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YxCqrebfvWwy"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "\n",
    "#load extracted info from annotations\n",
    "open_file = dictionary_file_path\n",
    "with open(open_file,'rb') as fp:    D = pickle.load(fp)\n",
    "\n",
    "\"\"\"\n",
    "{\n",
    "  \"filename\" : \"the full path to the image\",\n",
    "  \"id\" : \"an identifier for this image\",\n",
    "  'width':\n",
    "  'height':\n",
    "  \"class\" : {\n",
    "    \"label\" : \"integer in the range [0, num_classes)\",\n",
    "    \"text\" : \"a human readable string for this class\"\n",
    "  },\n",
    "  \"object\" : {\n",
    "    \"bbox\" : {\n",
    "      \"xmin\" : \"an array of float values\",\n",
    "      \"xmax\" : \"an array of float values\",\n",
    "      \"ymin\" : \"an array of float values\",\n",
    "      \"ymax\" : \"an array of float values\",\n",
    "      \"label\" : \"an array of integer values, in the range [0, num_classes)\",\n",
    "      \"count\" : \"an integer, the number of bounding boxes\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "#prepare a dict with the info needed for the next step of preparing the tf records\n",
    "#black mouse\n",
    "idg = 1\n",
    "v_infob = []\n",
    "for i in range(len(D)):\n",
    "    # image name and id\n",
    "    # bbox/label allows to separate between black or white mouse\n",
    "    # from the annotation 0 is the black mouse, 1 is the white mouse\n",
    "\n",
    "    B = D[i]['ann_B']['bbox']\n",
    "    W = D[i]['ann_W']['bbox']\n",
    "    i_frame = {'filename': im_path + D[i]['frame_name'],\n",
    "               \"class\": {\n",
    "                   \"label\": 0,\n",
    "                   \"text\": '',\n",
    "               },\n",
    "               'id':  format(idg, '06d'),\n",
    "               'width': D[i]['width'],\n",
    "               'height': D[i]['height'],\n",
    "               'object': {'area':[ D[i]['ann_B']['area']],\n",
    "                   'bbox': {\n",
    "                       'xmin': [B[0]],\n",
    "                       'xmax': [B[1]],\n",
    "                       'ymin': [B[2]],\n",
    "                       'ymax': [B[3]],\n",
    "                       'label':[0],\n",
    "                       'count': 1}}}\n",
    "    v_infob.append(i_frame)\n",
    "    idg += 1\n",
    "\n",
    "#white mouse\n",
    "idg = 1\n",
    "v_infow = []\n",
    "for i in range(len(D)):\n",
    "    print(i)\n",
    "    # image name and id\n",
    "    # bbox/label allows to separate between black or white mouse\n",
    "    # from the annotation 0 is the black mouse, 1 is the white mouse\n",
    "\n",
    "    B = D[i]['ann_B']['bbox']\n",
    "    W = D[i]['ann_W']['bbox']\n",
    "    i_frame = {'filename': im_path + D[i]['frame_name'],\n",
    "               \"class\": {\n",
    "                   \"label\": 0,\n",
    "                   \"text\": '',\n",
    "               },\n",
    "               'id':  format(idg, '06d'),\n",
    "               'width': D[i]['width'],\n",
    "               'height': D[i]['height'],\n",
    "               'object': {'area':[ D[i]['ann_W']['area']],\n",
    "                   'bbox': {\n",
    "                       'xmin': [W[0]],\n",
    "                       'xmax': [W[1]],\n",
    "                       'ymin': [W[2]],\n",
    "                       'ymax': [W[3]],\n",
    "                       'label':[0],\n",
    "                       'count': 1}}}\n",
    "    v_infow.append(i_frame)\n",
    "    idg += 1\n",
    "\n",
    "\n",
    "v_info = list(zip(v_infob, v_infow))\n",
    "random.shuffle(v_info)\n",
    "v_infob, v_infow = zip(*v_info)\n",
    "\n",
    "\n",
    "# prepare tf records dataset\n",
    "# split train val test\n",
    "n = len(v_infob)\n",
    "ntrain =int(math.floor(n * .85))\n",
    "nval = int(round(n * .05))\n",
    "ntest = int(round(n * .10))\n",
    "print(n, ntrain, nval, ntest)\n",
    "\n",
    "train = v_infob[:ntrain]\n",
    "val = v_infob[ntrain:ntrain + nval]\n",
    "test = v_infob[ntrain + nval:]\n",
    "\n",
    "# create tf records\n",
    "\n",
    "create(\n",
    "    dataset=train,\n",
    "    dataset_name=\"train_dataset\",\n",
    "    output_directory=detection_black_tfrecord_output_name,\n",
    "    num_shards=10,\n",
    "    num_threads=5,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "create(\n",
    "    dataset=val,\n",
    "    dataset_name=\"val_dataset\",\n",
    "    output_directory=detection_black_tfrecord_output_name,\n",
    "    num_shards=1,\n",
    "    num_threads=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "create(\n",
    "    dataset=test,\n",
    "    dataset_name=\"test_dataset\",\n",
    "    output_directory=detection_black_tfrecord_output_name,\n",
    "    num_shards=1,\n",
    "    num_threads=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "n = len(v_infow)\n",
    "ntrain =int(math.floor(n * .85))\n",
    "nval = int(round(n * .05))\n",
    "ntest = int(round(n * .10))\n",
    "print(n, ntrain, nval, ntest)\n",
    "\n",
    "train = v_infow[:ntrain]\n",
    "val = v_infow[ntrain:ntrain + nval]\n",
    "test = v_infow[ntrain + nval:]\n",
    "\n",
    "# create tf records\n",
    "create(\n",
    "    dataset=train,\n",
    "    dataset_name=\"train_dataset\",\n",
    "    output_directory=detection_white_tfrecord_output_name,\n",
    "    num_shards=10,\n",
    "    num_threads=5,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "create(\n",
    "    dataset=val,\n",
    "    dataset_name=\"val_dataset\",\n",
    "    output_directory=detection_white_tfrecord_output_name,\n",
    "    num_shards=1,\n",
    "    num_threads=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "create(\n",
    "    dataset=test,\n",
    "    dataset_name=\"test_dataset\",\n",
    "    output_directory=detection_white_tfrecord_output_name,\n",
    "    num_shards=1,\n",
    "    num_threads=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "manifest_to_tfrecord.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
