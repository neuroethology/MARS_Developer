{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create the tfrecord files for a dataset.\n",
    "A lot of this code comes from the tensorflow inception example, so here is their license:\n",
    "# Copyright 2016 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "###added  path to tfrecords features\n",
    "\"\"\"\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "from queue import Queue\n",
    "import sys\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import threading\n",
    "import random\n",
    "import pdb\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Wrapper for inserting int64 features into Example proto.\"\"\"\n",
    "  if not isinstance(value, list):\n",
    "    value = [value]\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Wrapper for inserting float features into Example proto.\"\"\"\n",
    "  if not isinstance(value, list):\n",
    "    value = [value]\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Wrapper for inserting bytes features into Example proto.\"\"\"\n",
    "  if isinstance(value, str):\n",
    "    value = value.encode('utf-8')\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _convert_to_example(image_example, image_buffer, height, width):\n",
    "  \"\"\"Build an Example proto for an example.\n",
    "  Args:\n",
    "    image_example: dict, an image example\n",
    "    image_buffer: string, JPEG encoding of RGB image\n",
    "    height: integer, image height in pixels\n",
    "    width: integer, image width in pixels\n",
    "  Returns:\n",
    "    Example proto\n",
    "  \"\"\"\n",
    "  \n",
    "  # Required\n",
    "  filename = str(image_example['filename'])\n",
    "  id = str(image_example['id'])\n",
    "  \n",
    "  # Class label for the whole image\n",
    "  image_class = image_example.get('class', {})\n",
    "  class_label = image_class.get('label', 0)\n",
    "  class_text = str(image_class.get('text', b''))\n",
    "  \n",
    "  # Bounding Boxes\n",
    "  image_objects = image_example.get('object', {})\n",
    "  image_bboxes = image_objects.get('bbox', {})\n",
    "  xmin = image_bboxes.get('xmin', [])\n",
    "  xmax = image_bboxes.get('xmax', [])\n",
    "  ymin = image_bboxes.get('ymin', [])\n",
    "  ymax = image_bboxes.get('ymax', [])\n",
    "  bbox_labels = image_bboxes.get('label', [])\n",
    "  bbox_scores = image_bboxes.get('score', [])\n",
    "  bbox_count = image_bboxes.get('count', 0)\n",
    "  \n",
    "  # Parts\n",
    "  image_parts = image_objects.get('parts', {})\n",
    "  parts_x = image_parts.get('x', [])\n",
    "  parts_y = image_parts.get('y', [])\n",
    "  parts_v = image_parts.get('v', [])\n",
    "  \n",
    "  # Areas\n",
    "  object_areas = image_objects.get('area', [])\n",
    "  \n",
    "  # Ids\n",
    "  object_ids = image_objects.get('id', [])\n",
    "  \n",
    "  colorspace = b'RGB'\n",
    "  channels = 3\n",
    "  image_format = b'JPEG'\n",
    "\n",
    "  example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': _int64_feature(height),\n",
    "      'image/width': _int64_feature(width),\n",
    "      'image/colorspace': _bytes_feature(colorspace),\n",
    "      'image/channels': _int64_feature(channels),\n",
    "      'image/class/label': _int64_feature(class_label),\n",
    "      'image/class/text': _bytes_feature(class_text),\n",
    "      'image/object/bbox/xmin': _float_feature(xmin),\n",
    "      'image/object/bbox/xmax': _float_feature(xmax),\n",
    "      'image/object/bbox/ymin': _float_feature(ymin),\n",
    "      'image/object/bbox/ymax': _float_feature(ymax),\n",
    "      'image/object/bbox/label': _int64_feature(bbox_labels),\n",
    "      'image/object/bbox/count' : _int64_feature(bbox_count),\n",
    "      'image/object/bbox/score' : _float_feature(bbox_scores),\n",
    "      'image/object/parts/x' : _float_feature(parts_x),\n",
    "      'image/object/parts/y' : _float_feature(parts_y),\n",
    "      'image/object/parts/v' : _int64_feature(parts_v),\n",
    "      'image/object/parts/count' : _int64_feature(len(parts_v)),\n",
    "      'image/object/area' : _float_feature(object_areas),\n",
    "      'image/object/id' : _int64_feature(object_ids),\n",
    "      'image/format': _bytes_feature(image_format),\n",
    "      'image/filename': _bytes_feature(os.path.basename(filename)),\n",
    "      'image/path': _bytes_feature(os.path.dirname(filename)),\n",
    "      'image/id': _bytes_feature(str(id)),\n",
    "      'image/encoded': _bytes_feature(image_buffer)}))\n",
    "  return example\n",
    "\n",
    "\n",
    "class ImageCoder(object):\n",
    "  \"\"\"Helper class that provides TensorFlow image coding utilities.\"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    # Create a single Session to run all image coding calls.\n",
    "    self._sess = tf.Session()\n",
    "\n",
    "    # Initializes function that converts PNG to JPEG data.\n",
    "    self._png_data = tf.placeholder(dtype=tf.string)\n",
    "    image = tf.image.decode_png(self._png_data, channels=3)\n",
    "    self._png_to_jpeg = tf.image.encode_jpeg(image, format='rgb', quality=100)\n",
    "\n",
    "    # Initializes function that decodes RGB JPEG data.\n",
    "    self._decode_jpeg_data = tf.placeholder(dtype=tf.string)\n",
    "    self._decode_jpeg = tf.image.decode_jpeg(self._decode_jpeg_data, channels=3)\n",
    "\n",
    "  def png_to_jpeg(self, image_data):\n",
    "    return self._sess.run(self._png_to_jpeg,\n",
    "                          feed_dict={self._png_data: image_data})\n",
    "\n",
    "  def decode_jpeg(self, image_data):\n",
    "    image = self._sess.run(self._decode_jpeg,\n",
    "                           feed_dict={self._decode_jpeg_data: image_data})\n",
    "    assert len(image.shape) == 3\n",
    "    assert image.shape[2] == 3\n",
    "    return image\n",
    "\n",
    "def _is_png(filename):\n",
    "  \"\"\"Determine if a file contains a PNG format image.\n",
    "  Args:\n",
    "    filename: string, path of the image file.\n",
    "  Returns:\n",
    "    boolean indicating if the image is a PNG.\n",
    "  \"\"\"\n",
    "  filepath, file_extension = os.path.splitext(filename)\n",
    "  if file_extension == '.png':\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def _process_image(filename, coder):\n",
    "  \"\"\"Process a single image file.\n",
    "  Args:\n",
    "    filename: string, path to an image file e.g., '/path/to/example.JPG'.\n",
    "    coder: instance of ImageCoder to provide TensorFlow image coding utils.\n",
    "  Returns:\n",
    "    image_buffer: string, JPEG encoding of RGB image.\n",
    "    height: integer, image height in pixels.\n",
    "    width: integer, image width in pixels.\n",
    "  \"\"\"\n",
    "  # Read the image file.\n",
    "  image_data = tf.gfile.FastGFile(filename, 'rb').read()\n",
    "\n",
    "  # Clean the dirty data.\n",
    "  if _is_png(filename):\n",
    "    # 1 image is a PNG.\n",
    "    #print('Converting PNG to JPEG for %s' % filename)\n",
    "    image_data = coder.png_to_jpeg(image_data)\n",
    "\n",
    "  # Decode the RGB JPEG.\n",
    "  image = coder.decode_jpeg(image_data)\n",
    "  # Check that image converted to RGB\n",
    "  assert len(image.shape) == 3\n",
    "  height = image.shape[0]\n",
    "  width = image.shape[1]\n",
    "  assert image.shape[2] == 3\n",
    "\n",
    "  return image_data, height, width\n",
    "\n",
    "\n",
    "def _process_image_files_batch(coder, thread_index, ranges, name, output_directory, dataset, num_shards, error_queue):\n",
    "  \"\"\"Processes and saves list of images as TFRecord in 1 thread.\n",
    "  Args:\n",
    "    coder: instance of ImageCoder to provide TensorFlow image coding utils.\n",
    "    thread_index: integer, unique batch to run index is within [0, len(ranges)).\n",
    "    ranges: list of pairs of integers specifying ranges of each batches to\n",
    "      analyze in parallel.\n",
    "    name: string, unique identifier specifying the data set (e.g. `train` or `test`)\n",
    "    output_directory: string, file path to store the tfrecord files.\n",
    "    dataset: list, a list of image example dicts\n",
    "    num_shards: integer number of shards for this data set.\n",
    "    error_queue: Queue, a queue to place image examples that failed.\n",
    "  \"\"\"\n",
    "  # Each thread produces N shards where N = int(num_shards / num_threads).\n",
    "  # For instance, if num_shards = 128, and the num_threads = 2, then the first\n",
    "  # thread would produce shards [0, 64).\n",
    "  num_threads = len(ranges)\n",
    "  assert not num_shards % num_threads\n",
    "  num_shards_per_batch = int(num_shards / num_threads)\n",
    "\n",
    "  shard_ranges = np.linspace(ranges[thread_index][0],\n",
    "                             ranges[thread_index][1],\n",
    "                             num_shards_per_batch + 1).astype(int)\n",
    "  num_files_in_thread = ranges[thread_index][1] - ranges[thread_index][0]\n",
    "\n",
    "  counter = 0\n",
    "  error_counter = 0\n",
    "  for s in range(num_shards_per_batch):\n",
    "    # Generate a sharded version of the file name, e.g. 'train-00002-of-00010'\n",
    "    shard = thread_index * num_shards_per_batch + s\n",
    "    output_filename = '%s-%.5d-of-%.5d' % (name, shard, num_shards)\n",
    "    output_file = os.path.join(output_directory, output_filename)\n",
    "    writer = tf.python_io.TFRecordWriter(output_file)\n",
    "\n",
    "    shard_counter = 0\n",
    "    files_in_shard = np.arange(shard_ranges[s], shard_ranges[s + 1], dtype=int)\n",
    "    for i in files_in_shard:\n",
    "      \n",
    "      image_example = dataset[i]\n",
    "      \n",
    "      filename = str(image_example['filename'])\n",
    "\n",
    "      try:\n",
    "        image_buffer, height, width = _process_image(filename, coder)\n",
    "\n",
    "        # if len(image_buffer) == 0:\n",
    "        #   print(image_buffer, height, width)\n",
    "        \n",
    "        example = _convert_to_example(image_example, image_buffer, height, width)\n",
    "        writer.write(example.SerializeToString())\n",
    "        shard_counter += 1\n",
    "        counter += 1\n",
    "      except Exception as e:\n",
    "        raise\n",
    "        error_counter += 1\n",
    "        error_queue.put(image_example)\n",
    "\n",
    "      if not counter % 1000:\n",
    "        print('%s [thread %d]: Processed %d of %d images in thread batch, with %d errors.' %\n",
    "              (datetime.now(), thread_index, counter, num_files_in_thread, error_counter))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    print('%s [thread %d]: Wrote %d images to %s, with %d errors.' %\n",
    "          (datetime.now(), thread_index, shard_counter, output_file, error_counter))\n",
    "    sys.stdout.flush()\n",
    "    shard_counter = 0\n",
    "    \n",
    "  print('%s [thread %d]: Wrote %d images to %d shards, with %d errors.' %\n",
    "        (datetime.now(), thread_index, counter, num_files_in_thread, error_counter))\n",
    "  sys.stdout.flush()\n",
    "  \n",
    "\n",
    "def create(dataset, dataset_name, output_directory, num_shards, num_threads, shuffle=True):\n",
    "  \"\"\"Create the tfrecord files to be used to train or test a model.\n",
    "  \n",
    "  Args:\n",
    "    dataset : [{\n",
    "      \"filename\" : <REQUIRED: path to the image file>, \n",
    "      \"id\" : <REQUIRED: id of the image>,\n",
    "      \"class\" : {\n",
    "        \"label\" : <[0, num_classes)>,\n",
    "        \"text\" : <text description of class>\n",
    "      },\n",
    "      \"object\" : {\n",
    "        \"bbox\" : {\n",
    "          \"xmin\" : [],\n",
    "          \"xmax\" : [],\n",
    "          \"ymin\" : [],\n",
    "          \"ymax\" : [],\n",
    "          \"label\" : []\n",
    "        }\n",
    "      }\n",
    "    }]\n",
    "    \n",
    "    dataset_name: a name for the dataset\n",
    "    \n",
    "    output_directory: path to a directory to write the tfrecord files\n",
    "    \n",
    "    num_shards: the number of tfrecord files to create\n",
    "    \n",
    "    num_threads: the number of threads to use \n",
    "    shuffle : bool, should the image examples be shuffled or not prior to creating the tfrecords.\n",
    "  \n",
    "  Returns:\n",
    "    list : a list of image examples that failed to process.\n",
    "  \"\"\"\n",
    "  \n",
    "  # Images in the tfrecords set must be shuffled properly\n",
    "  if shuffle:\n",
    "    random.shuffle(dataset)\n",
    "\n",
    "  # Break all images into batches with a [ranges[i][0], ranges[i][1]].\n",
    "  spacing = np.linspace(0, len(dataset), num_threads + 1).astype(np.int)\n",
    "  ranges = []\n",
    "  threads = []\n",
    "  for i in range(len(spacing) - 1):\n",
    "    ranges.append([spacing[i], spacing[i+1]])\n",
    "\n",
    "  # Launch a thread for each batch.\n",
    "  print('Launching %d threads for spacings: %s' % (num_threads, ranges))\n",
    "  sys.stdout.flush()\n",
    "\n",
    "  # Create a mechanism for monitoring when all threads are finished.\n",
    "  coord = tf.train.Coordinator()\n",
    "\n",
    "  # Create a generic TensorFlow-based utility for converting all image codings.\n",
    "  coder = ImageCoder()\n",
    "  \n",
    "  # A Queue to hold the image examples that fail to process. \n",
    "  error_queue = Queue()  \n",
    "  \n",
    "  threads = []\n",
    "  for thread_index in range(len(ranges)):\n",
    "    args = (coder, thread_index, ranges, dataset_name, output_directory, dataset, num_shards, error_queue)\n",
    "    t = threading.Thread(target=_process_image_files_batch, args=args)\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "  # Wait for all the threads to terminate.\n",
    "  coord.join(threads)\n",
    "  print('%s: Finished writing all %d images in data set.' %\n",
    "        (datetime.now(), len(dataset)))\n",
    "  \n",
    "  # Collect the errors\n",
    "  errors = []\n",
    "  while not error_queue.empty():\n",
    "    errors.append(error_queue.get())\n",
    "  print ('%d examples failed.' % (len(errors),))\n",
    "  \n",
    "  return errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
