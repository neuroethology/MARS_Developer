{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist, euclidean\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import s3fs\n",
    "fs = s3fs.S3FileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you'll need to check the folder name, eg black-100-1561503934, manually. It will be however you\n",
    "# defined job_name in run_labeling_jobs.\n",
    "# In the current code job_name is the bucket name plus a timestamp, so the most recent job output\n",
    "# will be the folder with the highest number at the end.\n",
    "\n",
    "lbl_bucket = 'black-100-output/black-100-1561503934'\n",
    "\n",
    "# first read the output manifest:\n",
    "fid = 's3://{}/manifests/output/output.manifest'.format(lbl_bucket)\n",
    "data = []\n",
    "for line in fs.open(fid,'r'):\n",
    "    data.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next we unpack the raw data from all individual annotators\n",
    "\n",
    "nSamp   = len(data)\n",
    "nKpts   = 7\n",
    "nWorkers = 6\n",
    "order   = ['nose','right ear','left ear','top of neck','right rear knee','left rear knee','base of tail']\n",
    "keyName = 'annotatedResult' # name for the dict containing annotation data- this was set in run_labeling_job\n",
    "\n",
    "\n",
    "# for each image: 7 keypoints, 2 dimensions, 6 workers per keypoint\n",
    "rawPts = {'black': np.zeros((nSamp,nKpts,2,nWorkers)), 'white': np.zeros((nSamp,nKpts,2,nWorkers))}\n",
    "\n",
    "images = ['']*nSamp        # track paths to labeled images\n",
    "hits = [False]*nSamp       # track which images have annotations (only needed if a job failed to complete)\n",
    "workerCount = [0]*nSamp    # track the number of workers who labeled each image (only needed if a job failed to complete)\n",
    "\n",
    "sourceStr = os.path.dirname(data[0]['source-ref'])\n",
    "\n",
    "for f,frame in enumerate(data):\n",
    "    if (keyName in frame.keys()): #check if this frame has at least one set of annotations\n",
    "        hits[f] = True\n",
    "\n",
    "        images[f] = frame['source-ref']\n",
    "\n",
    "        for w,worker in enumerate(frame[keyName]['annotationsFromAllWorkers']):\n",
    "            workerCount[f] = workerCount[f] + 1\n",
    "\n",
    "            # the json of annotations from each worker is stored as a string for security reasons.\n",
    "            # we'll use eval to convert it into a dict:\n",
    "            annot = eval(worker['annotationData']['content'])\n",
    "\n",
    "            # now we can unpack this worker's annotations for each keypoint:\n",
    "            for pt in annot[keyName]['keypoints']:\n",
    "                mouse = 'black' if 'black' in pt['label'] else 'white'\n",
    "                idx = order.index(pt['label'].replace(mouse,'').replace('mouse','').strip())\n",
    "                \n",
    "                rawPts[mouse][f,idx,0,w] = pt['x']\n",
    "                rawPts[mouse][f,idx,1,w] = pt['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're going to set our ground-truth points as the geometric median of all the annotators.\n",
    "# This algorithm for the geometric median comes from Vardi and Zhang 1999, as implemented by orlp on Stack Overflow\n",
    "# (https://stackoverflow.com/questions/30299267/geometric-median-of-multidimensional-points)\n",
    "\n",
    "def geometric_median(X, eps=1e-1):\n",
    "    y = np.mean(X, 0)\n",
    "    \n",
    "    count=0\n",
    "    while True:\n",
    "        count=count+1\n",
    "        D = cdist(X, [y])\n",
    "        nonzeros = (D != 0)[:, 0]\n",
    "\n",
    "        Dinv = 1 / D[nonzeros]\n",
    "        Dinvs = np.sum(Dinv)\n",
    "        W = Dinv / Dinvs\n",
    "        T = np.sum(W * X[nonzeros], 0)\n",
    "\n",
    "        num_zeros = len(X) - np.sum(nonzeros)\n",
    "        if num_zeros == 0:\n",
    "            y1 = T\n",
    "        elif num_zeros == len(X):\n",
    "            return y\n",
    "        else:\n",
    "            R = (T - y) * Dinvs\n",
    "            r = np.linalg.norm(R)\n",
    "            rinv = 0 if r == 0 else num_zeros/r\n",
    "            y1 = max(0, 1-rinv)*T + min(1, rinv)*y\n",
    "\n",
    "        if euclidean(y, y1) < eps:\n",
    "            return y1\n",
    "        \n",
    "        if count>10:\n",
    "            return y1\n",
    "\n",
    "        y = y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's get our ground-truth keypoints. (Note: this cell is slow!)\n",
    "\n",
    "gtPts  = {'white':[],'black':[]}\n",
    "allPts = {'white':[],'black':[]}\n",
    "\n",
    "for mouse in ['white','black']:\n",
    "    #first we'll take medians of the raw keypoints:\n",
    "    gtPts[mouse] = np.zeros((nSamp,nKpts,2))\n",
    "    for f,frame in enumerate(rawPts[mouse]):\n",
    "        for p,pt in enumerate(frame):\n",
    "            gtPts[mouse][f,p,:] = geometric_median(np.squeeze(pt.T))\n",
    "\n",
    "    # then we'll adjust L/R assignments to try to find better median estimates. Iterating\n",
    "    # seems to help settle on better final keypoints if the initial guesses were especially bad.\n",
    "    for rep in range(3):\n",
    "        # for ears and hips we should check for + correct Left/Right swaps, a common annotator mistake:\n",
    "        allPts[mouse] = np.copy(rawPts[mouse])\n",
    "        \n",
    "        for fr,(gt,frame) in enumerate(zip(gtPts[mouse],rawPts[mouse])):\n",
    "            for w,worker in enumerate(frame.swapaxes(0,2).swapaxes(1,2)):\n",
    "                \n",
    "                dEar1 = cdist(worker[1:3,:],[gt[1]])\n",
    "                dEar2 = cdist(worker[1:3,:],[gt[2]])\n",
    "                if (dEar1[0]>dEar1[1]) and (dEar2[1]>dEar1[0]):\n",
    "                    allPts[mouse][fr,1,:,w] = rawPts[mouse][fr,2,:,w]\n",
    "                    allPts[mouse][fr,2,:,w] = rawPts[mouse][fr,1,:,w]\n",
    "                \n",
    "                dHip1 = cdist(worker[4:6,:],[gt[4]])\n",
    "                dHip2 = cdist(worker[4:6,:],[gt[5]])\n",
    "                if (dHip1[0]>dHip1[1]) and (dHip2[1]>dHip2[0]):\n",
    "                    allPts[mouse][fr,4,:,w] = rawPts[mouse][fr,5,:,w]\n",
    "                    allPts[mouse][fr,5,:,w] = rawPts[mouse][fr,4,:,w]\n",
    "\n",
    "        # then re-compute the medians:\n",
    "        gtPts[mouse] = np.zeros((nSamp,nKpts,2))\n",
    "        for f,frame in enumerate(allPts[mouse]):\n",
    "            for p,pt in enumerate(frame):\n",
    "                gtPts[mouse][f,p,:] = geometric_median(np.squeeze(pt.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at a couple example images to see how our annotators did.\n",
    "# (note, this also saves the figure as a pdf in lbl_bucket):\n",
    "\n",
    "# each body part gets an assigned color; each annotator gets an assigned marker.\n",
    "colors  = 'rgbcmyw'\n",
    "markers = 'v+xosd'\n",
    "\n",
    "fig,ax = plt.subplots(5,2,figsize=(16, 30))\n",
    "for fr in range(0,10):\n",
    "    im = mpimg.imread(images[fr])\n",
    "    ax[int(fr/2),(fr+1)%2].imshow(im);\n",
    "    \n",
    "    # plot the labels from each individual worker:\n",
    "    for mouse,mouseColor in zip(['white','black'],['w','k']):\n",
    "        for p,pt in enumerate(np.squeeze(allPts[mouse][fr,...])):\n",
    "            for w in range(nWorkers):\n",
    "                ax[int(fr/2),(fr+1)%2].plot(pt[0,w], pt[1,w],colors[p] + markers[w], markersize=2,markeredgecolor=mouseColor)\n",
    "\n",
    "        # plot the \"ground truth\" labels:\n",
    "        ax[int(fr/2),(fr+1)%2].plot(gtPts[mouse][fr,:,0], gtPts[mouse][fr,:,1],'k.', markersize=4)\n",
    "\n",
    "fig.savefig('s3://{}/sample_annotations.pdf'.format(lbl_bucket), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we'd like to quantify annotator variability. For some reason, this seems to be a good predictor\n",
    "# of how well our pose estimator is going to do once trained.\n",
    "\n",
    "pixels_per_cm = 37.795\n",
    "\n",
    "fig,ax = plt.subplots(2,4,figsize=(16, 8))\n",
    "dashes = {'white':'dotted', 'black':'dashed', 'both':'solid'}\n",
    "colors = 'rbg'\n",
    "\n",
    "for mouse in ['white','black','both']:\n",
    "    if mouse != 'both':\n",
    "        dMean = np.zeros((nKpts,nSamp)) # average worker-gt distance\n",
    "        dMin  = np.zeros((nKpts,nSamp)) # performance of best worker on a given frame\n",
    "        dMax  = np.zeros((nKpts,nSamp)) # performance of worst worker on a given frame\n",
    "        for fr,(gt,est) in enumerate(zip(gtPts[mouse],allPts[mouse])):\n",
    "            for pt,(gtPt,estPts) in enumerate(zip(gt,est)):\n",
    "                D = cdist(estPts.T, [gtPt]) / pixels_per_cm\n",
    "                dMean[pt,fr] = np.mean(D)\n",
    "                dMin[pt,fr]  = min(D)\n",
    "                dMax[pt,fr]  = max(D)\n",
    "    else:\n",
    "        dMean = np.zeros((nKpts,nSamp*2))\n",
    "        dMin  = np.zeros((nKpts,nSamp*2))\n",
    "        dMax  = np.zeros((nKpts,nSamp*2))\n",
    "        for fr,(gt,est) in enumerate(zip(np.concatenate((gtPts['white'],gtPts['black'])), \\\n",
    "                                        np.concatenate((allPts['white'],allPts['black'])))):\n",
    "            for pt,(gtPt,estPts) in enumerate(zip(gt,est)):\n",
    "                D = cdist(estPts.T, [gtPt]) / pixels_per_cm\n",
    "                dMean[pt,fr] = np.mean(D)\n",
    "                dMin[pt,fr]  = min(D)\n",
    "                dMax[pt,fr]  = max(D)\n",
    "\n",
    "    showMax = 3\n",
    "    bins = 10000\n",
    "    binrange = [-1/bins, 500]\n",
    "\n",
    "    for c,use in enumerate([dMin,dMean,dMax]):\n",
    "        for p,pt in enumerate(use):\n",
    "            counts,usedbins = np.histogram(pt,bins,range=binrange,density=True)\n",
    "            ax[int(p/4),p%4].plot(usedbins[1:], counts.cumsum()/bins*binrange[1], colors[c], ls=dashes[mouse])\n",
    "            ax[int(p/4),p%4].set_title(order[p])\n",
    "            ax[int(p/4),p%4].set_xlim([0,showMax])\n",
    "            ax[int(p/4),p%4].plot([1,1],[0,1],'k--')\n",
    "            ax[int(p/4),p%4].plot([0,showMax],[.8,.8],'k--')\n",
    "\n",
    "        counts,usedbins = np.histogram(use.ravel(),bins,range=binrange,density=True)\n",
    "        ax[1,3].plot(usedbins[1:], counts.cumsum()/bins*binrange[1], colors[c], ls=dashes[mouse])\n",
    "        ax[1,3].plot([1,1],[0,1],'k--')\n",
    "        ax[1,3].plot([0,showMax],[.8,.8],'k--')\n",
    "        ax[1,3].set_title('all');\n",
    "        ax[1,3].set_xlim([0,showMax])\n",
    "\n",
    "fig.savefig('s3://{}/performance.pdf'.format(lbl_bucket), bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
