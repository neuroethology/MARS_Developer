{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creating TFRecords**\n",
    "In order to train the multibox detector on your own data, you need to generate tfrecords from your own data.\n",
    "\n",
    "### **Arguments**\n",
    "* **dataset**: A list of dictionaries where each entry includes one or multiple bounding boxes. **IMPORTANT** Entries to the list must be specified in the dictionary format shown below.\n",
    "* **dataset_name**: The name to save the dataset as.\n",
    "* **output_dir**: The directory to save the tfrecords file to.\n",
    "* **num_shards**: Number of files to split **dataset** into.\n",
    "* **num_threads**: Number of threads to use while converting **dataset** into tfrecords.\n",
    "* **shuffle**: Bool specifying whether to shuffle the data before writing to tfrecords or not.\n",
    "\n",
    "### **Outputs**\n",
    "Will save a tfrecords file with the name **dataset_name** in the directory specified by **output_dir**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 1 threads for spacings: [[0, 1]]\n",
      "WARNING:tensorflow:From /home/andrew_work/MARS_Developer/multibox_detection/create_tfrecords.py:133: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/andrew_work/MARS_Developer/multibox_detection/create_tfrecords.py:136: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/andrew_work/MARS_Developer/multibox_detection/create_tfrecords.py:230: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/andrew_work/MARS_Developer/multibox_detection/create_tfrecords.py:179: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/andrew_work/miniconda3/envs/draft_mars_dev/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/andrew_work/miniconda3/envs/draft_mars_dev/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/andrew_work/MARS_Developer/multibox_detection/create_tfrecords.py\", line 241, in _process_image_files_batch\n",
      "    image_buffer, height, width = _process_image(filename, coder)\n",
      "  File \"/home/andrew_work/MARS_Developer/multibox_detection/create_tfrecords.py\", line 179, in _process_image\n",
      "    image_data = tf.gfile.FastGFile(filename, 'r').read()\n",
      "  File \"/home/andrew_work/miniconda3/envs/draft_mars_dev/lib/python3.7/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 122, in read\n",
      "    self._preread_check()\n",
      "  File \"/home/andrew_work/miniconda3/envs/draft_mars_dev/lib/python3.7/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 84, in _preread_check\n",
      "    compat.as_bytes(self.__name), 1024 * 512)\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: sample_1; No such file or directory\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-19 13:00:42.545207: Finished writing all 1 images in data set.\n",
      "0 examples failed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import create_tfrecords\n",
    "\n",
    "## This is a sample list entry for the dataset\n",
    "## All list elements in the dictionary accept multiple values to specify multiple bboxes.\n",
    "data = {'filename': 'sample_1',\n",
    "        'id': '1',\n",
    "        'class': {\n",
    "            'label': [0],\n",
    "            'text': b'mouse',\n",
    "            },\n",
    "        'object': {\n",
    "            # Each of the bbox coords (xmax, xmin, ymax, ymin) must be floats\n",
    "            'bbox': {\n",
    "                'xmax': [100.0], \n",
    "                'xmin': [0.0],\n",
    "                'ymax': [100.0],\n",
    "                'ymin': [0.0],\n",
    "                'label': [0],\n",
    "                'count': 1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Input to createtfrecords must be a list\n",
    "dataset = [data]\n",
    "\n",
    "# Call to tfrecords\n",
    "create_tfrecords.create(dataset,\n",
    "                        dataset_name = 'sample',\n",
    "                        output_directory = './',\n",
    "                        num_shards = 1,\n",
    "                        num_threads = 1,\n",
    "                        shuffle = True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training MARS Multibox Detector**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Arguments\n",
    "* **tfrecords**: path to the binary file(s) that contain your training set. If multiple files, separate with commas.\n",
    "* **logdir**: path to directory where summary and checkpoint files will be stored.\n",
    "* **cfg**: path to training configuration file.\n",
    "* **bbox_priors**: path to the bounding box priors pickle file.\n",
    "\n",
    "### Optional Arguments\n",
    "* **pretrained_model**: Path to continue training a pretrained Inception-v3 model.\n",
    "* **trainable_scopes**: Comma-separated list of scopes to filter the set of variables to train.\n",
    "* **use_moving_averages**: If True, then the moving averages will be used for each model variable from the pretrained network.\n",
    "* **restore_moving_averages**: If True, then the moving averages themselves be restored from the pretrained network.\n",
    "* **max_number_of_steps**: The maximum number of iterations to run.\n",
    "* **batch_size**: The batch size.\n",
    "\n",
    "The example below assumes the current working directory is the `multibox_detector` directory, which contains `train.py`. To train the multibox detector with the required arguments, simply replace the areas indicated below with the appropriate paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import train\n",
    "import pickle\n",
    "import config\n",
    "import numpy as np\n",
    "\n",
    "# Paths\n",
    "cfg_path = 'absolute/path/to/your/config/file.yaml'\n",
    "priors_path = 'absolute/path/to/your/config/file.yaml'\n",
    "tfrecords_path = ['absolute/path/to/your/tfrecords/file(s)'] # Separate multiple training data files with ','\n",
    "logdir_path = 'absolute/path/to/your/logging/directory'\n",
    "\n",
    "# Configuration file\n",
    "cfg = config.parse_config_file(cfg_path)\n",
    "\n",
    "# Load priors into numpy array\n",
    "with open(priors_path, 'rb') as f:\n",
    "    bbox_priors = pickle.load(f, encoding='latin1')\n",
    "bbox_priors = np.array(bbox_priors).astype(np.float32)\n",
    "\n",
    "# Call training function\n",
    "train.train(\n",
    "        tfrecords=tfrecords_path,\n",
    "        bbox_priors=bbox_priors,\n",
    "        logdir=logdir_path,\n",
    "        cfg=cfg\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Training Data\n",
    "### Required Arguments\n",
    "* **tfrecords**: path to the binary file(s) that contain your training set. If multiple files, separate with commas.\n",
    "* **cfg**: path to training configuration file.\n",
    "### Outputs\n",
    "* Displays each training image with its corresponding bounding box drawn over it - cycle through by hitting the enter key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize_inputs import visualize\n",
    "from config import parse_config_file\n",
    "\n",
    "# Paths\n",
    "cfg_path = 'absolute/path/to/your/config/file.yaml'\n",
    "tfrecords_path = ['absolute/path/to/your/tfrecords/file(s)'] # Separate multiple training data files with ','\n",
    "\n",
    "# Parse config file\n",
    "cfg = parse_config_file(cfg_path)\n",
    "\n",
    "# Call visualization function - hit enter to cycle through image\n",
    "visualize(\n",
    "    tfrecords=tfrecords_path,\n",
    "    cfg=cfg\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Priors Files\n",
    "### Required Arguments\n",
    "* **dataset**: path to either a tfrecord or pkl file to generate aspect ratios and priors.\n",
    "### Optional Arguments\n",
    "* **aspect_ratios**: list of hand-defined aspect ratios to use in generating the priors.\n",
    "### Outputs\n",
    "* **(dataset)-priors.pkl**: pkl file containing the priors generated from the training set where (dataset) is the file name of the dataset provided.\n",
    "\n",
    "**OR**\n",
    "\n",
    "* **priors_hand_gen.pkl**: pkl file containing the hand generated priors\n",
    "This will only generate priors from the training data if the `dataset` argument is provided. If the `aspect_ratio` argument is provided then this will generate priors from the hand-defined aspect ratios. Provide the `aspect_ratio` argument in the same format as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from priors_generator import generate_priors_from_data\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "# Example call generating priors from the dataset\n",
    "dataset = 'absolute/path/to/your/tfrecords/file'\n",
    "aspect_ratios = None\n",
    "\n",
    "p_1 = generate_priors_from_data(\n",
    "            dataset=dataset,\n",
    "            aspect_ratios=aspect_ratios\n",
    "        )\n",
    "\n",
    "# Example call generating priors from hand-defined aspect ratios\n",
    "dataset = None\n",
    "aspect_ratios = [1, 2, 3, 4, 5, 6, 1./2, 1./3, 1./4, 1./5]\n",
    "\n",
    "p_2 = generate_priors_from_data(\n",
    "            dataset=dataset,\n",
    "            aspect_ratios=aspect_ratios\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating MARS Multibox Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Arguments\n",
    "* **tfrecords**: path to the binary file that the image data from your validation set. If multiple files, separate with commas.\n",
    "* **summary_dir**: path to directory where summary and checkpoint files will be stored - be sure to include a `/` at the end of the path.\n",
    "* **checkpoint_path**: Either a path to a specific model, or a path to a directory where checkpoint files are stored. If a directory, the latest model will be tested against.\n",
    "* **priors**: path to the bounding box priors pickle file.\n",
    "* **config**: path to validation configuration file.\n",
    "\n",
    "### Optional Arguments\n",
    "* **max_iterations**: Maximum number of interations to run.\n",
    "\n",
    "The example below assume the current working directory is the `multibox_detector` directory, which contains `evaluation/eval.py`. To evaluate the multibox detector with the required arguments, simply replace the areas indicated below with the appropriate paths. \n",
    "\n",
    "### Outputs\n",
    "* **(summary_dir)/cocoEval.pkl**: pickle file that stores evaluation data used to compute the precision-recall (PR) curves for various Intersection over Union bounds `[IoU > 0.5, IoU > 0.75, IoU > 0.85, IoU > 0.9, IoU > 0.95]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import parse_config_file\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('./evaluation/')\n",
    "from evaluation.eval import eval\n",
    "\n",
    "# Paths\n",
    "cfg_path = 'absolute/path/to/your/config/file.yaml'\n",
    "priors_path = 'absolute/path/to/your/config/file.yaml'\n",
    "tfrecords_path = ['absolute/path/to/your/tfrecords/file(s)'] # Separate multiple training data files with ','\n",
    "summary_dir = 'absolute/path/to/your/summary/directory'\n",
    "checkpoint_path = 'absolute/path/to/your/model/training/checkpoint'\n",
    "\n",
    "# Parse config file\n",
    "cfg = parse_config_file(cfg_path)\n",
    "\n",
    "# Load priors into numpy array\n",
    "with open(priors_path, 'rb') as f:\n",
    "    bbox_priors = pickle.load(f, encoding='latin1')\n",
    "bbox_priors = np.array(bbox_priors).astype(np.float32)\n",
    "\n",
    "# Call evaluation function\n",
    "eval(\n",
    "    tfrecords=tfrecords_path,\n",
    "    bbox_priors=bbox_priors,\n",
    "    summary_dir=sumary_dir,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    max_iterations = 1,\n",
    "    cfg=cfg\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Validation Performance\n",
    "### Required Arguments\n",
    "* **cocoEval**: path to the file containing the cocoEval.pkl file described above - don't forget the `/` at the end.\n",
    "* **save_name**: path to save the precision-recall curve to.\n",
    "\n",
    "### Outputs\n",
    "* **(save_name).pdf**: pdf containing the PR curve described above.\n",
    "* **(save_name).png**: png version of the pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "sys.path.append('./evaluation/')\n",
    "from prcurve_separate import pr_curve\n",
    "\n",
    "# Paths\n",
    "summary_dir = 'absolute/path/to/your/summary/directory' # Same summary dir as in 'Evaluating MARS Multibox Detector'\n",
    "\n",
    "# Load cocoEval file\n",
    "save_name = summary_dir +'pr_curve'\n",
    "with open(summary_dir + 'cocoEval.pkl', 'rb') as fp: cocoEval = pickle.load(fp)\n",
    "\n",
    "# Make Precision-Recall curve\n",
    "pr_curve(cocoEval, save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing MARS Multibox Detector\n",
    "\n",
    "### Required Arguments\n",
    "* **tfrecords**: path to the binary file that contains your testing set.\n",
    "* **cfg**: path to testing configuration file.\n",
    "* **bbox_priors**: numpy array of bbox priors\n",
    "* **checkpoint_path**: Either a path to a specific model, or a path to a directory where checkpoint files are stored. If a directory, the latest model will be tested against.\n",
    "* **save_dir**: path to directory where you would like to store the json file containing the test results.\n",
    "\n",
    "### Optional Arguments\n",
    "* **max_iterations**: Maximum number of detections to store per image.\n",
    "* **max_detections**: Maximum number of iterations to run. Set to 0 to run on all records.\n",
    "\n",
    "The example below assumes the current working directory is the `multibox_detector` directory, which contains `detect.py`.\n",
    "\n",
    "### Outputs\n",
    "* **results**: JSON file stored the results for the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detect\n",
    "import pickle\n",
    "from config import parse_config_file\n",
    "import numpy as np\n",
    "\n",
    "# Paths\n",
    "cfg_path = 'absolute/path/to/your/config/file.yaml'\n",
    "priors_path = 'absolute/path/to/your/config/file.yaml'\n",
    "tfrecords_path = ['absolute/path/to/your/tfrecords/file(s)'] # Separate multiple training data files with ','\n",
    "save_dir = 'absolute/path/to/your/save/directory'\n",
    "checkpoint_path = 'absolute/path/to/your/model/training/checkpoint'\n",
    "\n",
    "# Parse configuration file \n",
    "cfg = parse_config_file(cfg_path)\n",
    "\n",
    "# Load in bbox priors\n",
    "with open(priors_path, 'rb') as f:\n",
    "    # bbox_priors = pickle.load(f)\n",
    "    u = pickle._Unpickler(f)\n",
    "    u.encoding = 'latin1'\n",
    "    bbox_priors = u.load()\n",
    "    bbox_priors = np.array(bbox_priors).astype(np.float32)    \n",
    "\n",
    "# Run detection\n",
    "detect.detect(\n",
    "    tfrecords=tfrecords_path,\n",
    "    bbox_priors=bbox_priors,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    save_dir = save_dir,\n",
    "    max_detections = 100,\n",
    "    max_iterations = 0,\n",
    "    cfg=cfg\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Test Performance\n",
    "### Required Arguments\n",
    "* **tfrecords**: path to the binary file that contains your testing set.\n",
    "* **config**: path to testing configuration file.\n",
    "* **priors**: path to the bounding box priors pickle file.\n",
    "* **checkpoint_path**: Either a path to a specific model, or a path to a directory where checkpoint files are stored. If a directory, the latest model will be tested against.\n",
    "\n",
    "### Outputs\n",
    "* The testing images with their corresponding bounding boxes drawn over them - click through by hitting the enter key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualize_detect\n",
    "from config import parse_config_file\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Paths\n",
    "cfg_path = 'absolute/path/to/your/config/file.yaml'\n",
    "priors_path = 'absolute/path/to/your/config/file.yaml'\n",
    "tfrecords_path = ['absolute/path/to/your/tfrecords/file(s)'] # Separate multiple training data files with ','\n",
    "save_dir = 'absolute/path/to/your/save/directory'\n",
    "checkpoint_path = 'absolute/path/to/your/model/training/checkpoint'\n",
    "\n",
    "# Parse config file\n",
    "cfg = parse_config_file('/home/andrew_work/nu/data/detection_top/config_test.yaml')\n",
    "\n",
    "# Load priors into numpy array\n",
    "with open('/home/andrew_work/nu/data/detection_top/priors_black_top.pkl', \"rb\") as f:\n",
    "    bbox_priors = pickle.load(f, encoding=\"latin1\")\n",
    "bbox_priors = np.array(bbox_priors).astype(np.float32)\n",
    "  \n",
    "# Image + predicted bounding box. Press enter key to cycle through\n",
    "visualize_detect.detect_visualize(\n",
    "    tfrecords=tfrecords_path,\n",
    "    bbox_priors=bbox_priors,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    cfg=cfg\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:draft_mars_dev]",
   "language": "python",
   "name": "conda-env-draft_mars_dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
