{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full MARS demo\n",
    "\n",
    "This is the tutorial from the readme of MARS_Developer in Jupyter notebook form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. üìÅ Create a new MARS Training Project\n",
    "\n",
    "Your MARS project directory will contain all the files created during the process of training MARS detector and pose models on your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project my_project created successfully.\n"
     ]
    }
   ],
   "source": [
    "from create_new_project import *\n",
    "# TODO: find less clunky way to call these scripts from Jupyter\n",
    "\n",
    "location = 'K:/'\n",
    "name = 'my_project'\n",
    "\n",
    "create_new_project(location, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** provide instructions on how to set up the fields of project_config.yaml."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ‚úçÔ∏è Collect a set of manually annotated animal poses.\n",
    "\n",
    "#### 2.1 Extract video frames that you would like to annotate.\n",
    "First, we need to collect a set of video frames to annotate. The script `extract_frames.py` will sample frames from all videos found in a directory, and save those frames as jpg files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python extract_raw_frames.py input_dir /path/to/videodir project /path/to/savedir/my_project n_frames 500\n",
    "# TODO: wrap and test this; add Util to MARS_Developer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now have a folder `my_project/annotation_data` containing a directory `raw_images` of video frames.\n",
    "\n",
    "#### 2.2 Run a labeling job.\n",
    "Refer to [these instructions](https://github.com/neuroethology/MARS_Developer/blob/develop/pose_annotation_tools/docs/readme_groundTruthSetup.md) to run a labeling job on Amazon SageMaker.\n",
    "\n",
    "This job will produce a file called `output.manifest` which you should add to `my_project/annotation_data`. If you change the name of this manifest file, be sure to update the `manifest_name` field of `my_project/project_config.yaml` appropriately.\n",
    "\n",
    "#### 2.3 Post-process the manual pose annotations.\n",
    "This will create \"ground truth\" keypoint locations by taking the median across AWS workers, and correct for left/right flips of body part labels. The processed annotation data will be added as a new file to `annotation_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing manifest file...\n",
      "  frame 1000\n",
      "  frame 2000\n",
      "  frame 3000\n",
      "  frame 4000\n",
      "  frame 5000\n",
      "Ground-truth keypoint locations extracted!\n"
     ]
    }
   ],
   "source": [
    "from pose_annotation_tools.json_util import *\n",
    "\n",
    "project_path = 'K:\\my_project'\n",
    "\n",
    "manifest_to_dict(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. üéØ Fine-tune the MARS detector to your data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mars",
   "language": "python",
   "name": "mars"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
