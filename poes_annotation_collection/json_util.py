import numpy as np
import os
import json
from scipy.spatial.distance import cdist, euclidean


def manifest_to_dict(manifest_file, im_path, save_file, keypoint_names, manifest_key='annotatedResult'):
    """
    Converts an annotation file generated by AMT/Ground Truth into the MARS json format.
    """

    nKpts = len(keypoint_names) # fix this, if we have two mice their keypoints will have different names

    fid = open(manifest_file, 'r')
    data = []
    for line in fid:
        data.append(json.loads(line))

    # loop over frames in the manifest file
    errors = []
    D = []
    for f, sample in enumerate(data):
        # Use the path to the image data to open the image.
        im = Image.open(im_path + data[f]['source-ref'].split('/')[-1])
        im = (np.asarray(im)).astype(float)

        # extract info for each worker
        XB, YB, XW, YW = ([] for i in range(4))
        for w, worker in enumerate(sample[manifest_key]['annotationsFromAllWorkers']):
            # the json of annotations from each worker is stored as a string for security reasons.
            # we'll use eval to convert it into a dict:
            points_dict = eval(worker['annotationData']['content'])

            black_mouse_x = [0] * nKpts
            black_mouse_y = [0] * nKpts
            white_mouse_x = [0] * nKpts
            white_mouse_y = [0] * nKpts
            for pt in points_dict[manifest_key]['keypoints']:
                mouse = 'black' if 'black' in pt['label'] else 'white'
                idx = keypoint_names.index(pt['label'].replace(mouse ,'').replace('mouse' ,'').strip())

                if mouse == 'black':
                    black_mouse_x[idx] = pt['x']/im.shape[1]
                    black_mouse_y[idx] = pt['y']/im.shape[0]
                else:
                    white_mouse_x[idx] = pt['x']/im.shape[1]
                    white_mouse_y[idx] = pt['y']/im.shape[0]
            XB.append(black_mouse_x)
            YB.append(black_mouse_y)
            XW.append(white_mouse_x)
            YW.append(white_mouse_y)

        # Compute some statistics for the tfrecord and append.
        frame_dict = make_frame_dict(XB, YB, XW, YW, keypoint_names, im.shape, sample['source-ref'].split('/')[-1])
        D.append(frame_dict)

    # save info to file
    with open(save_file, 'w') as fp:
        json.dump(D,fp)


def csv_to_dict(csv_file, im_path, save_file, keypoint_names=[]):
    """
    Converts manual annotations created by DeepLabCut from csv into the format created by MARS from
    AMT or Ground Truth manifest files. MARS can then use that json to create tfrecords for training
    the detection and pose models.
    """
    with open(csv_file) as datafile:
        next(datafile)
        if "individuals" in next(datafile):
            header = list(range(4))
            multianimal = True
        else:
            header = list(range(3))
            multianimal = False
    data = pd.read_csv(csv_file, index_col=0, header=header)

    worker_names = list(set(list(data.columns.get_level_values(0))))  # find all the annotators.
    if not keypoint_names:
        keypoint_names = list(data.columns.get_level_values(1))      # find all the keypoints.
        keypoint_names = list(OrderedDict.fromkeys(keypoint_names))  # get rid of redundancies while preserving order.

    nKpts = len(keypoint_names)

    # loop over frames in the manifest file
    errors = []
    D = []
    for f, image in enumerate(data.index):

        # Use the path to the image data to open the image.
        im = Image.open(im_path + os.path.split(image)[-1])
        im = (np.asarray(im)).astype(float)

        # convert our dataframe to a dict
        annot = data.loc[image]
        # TODO: update this to handle the multianimal case.
        annot = {level0: {level1: annot.xs([level0, level1]).to_dict() for level1 in annot.index.levels[1]}
                 for level0 in annot.index.levels[0]}

        # extract info for each worker
        XB, YB, XW, YW = ([] for i in range(4))
        for w, worker in annot.items():
            black_mouse_x = [0.] * nKpts
            black_mouse_y = [0.] * nKpts
            white_mouse_x = [0.] * nKpts
            white_mouse_y = [0.] * nKpts

            for label,pt in worker.items():
                # todo: get color if none was provided!
                mouse = 'white' if 'white' in label else 'black' # if no color was provided, assume black
                idx = keypoint_names.index(label.replace(mouse ,'').replace('mouse' ,'').strip())

                if mouse == 'black':
                    black_mouse_x[idx] = pt['x']/im.shape[1]
                    black_mouse_y[idx] = pt['y']/im.shape[0]
                else:
                    white_mouse_x[idx] = pt['x']/im.shape[1]
                    white_mouse_y[idx] = pt['y']/im.shape[0]

            XB.append(black_mouse_x)
            YB.append(black_mouse_y)
            XW.append(white_mouse_x)
            YW.append(white_mouse_y)

        # Compute some statistics for the tfrecord and append.
        frame_dict = make_frame_dict(XB, YB, XW, YW, keypoint_names, im.shape, os.path.split(image)[-1])
        D.append(frame_dict)

    # save info to file
    with open(save_file, 'w') as fp:
        json.dump(D, fp)


def make_frame_dict(XB, YB, XW, YW, keypoint_names, im_shape, im_name):
    XB = np.array(XB)
    YB = np.array(YB)
    XW = np.array(XW)
    YW = np.array(YW)

    mXB = geometric_median(XB) if len(XB) > 1 else XB[0]
    mYB = geometric_median(YB) if len(YB) > 1 else YB[0]
    mXW = geometric_median(XW) if len(XW) > 1 else XW[0]
    mYW = geometric_median(YW) if len(YW) > 1 else YW[0]

    muXB = np.mean(XB, axis=0)
    muYB = np.mean(YB, axis=0)
    muXW = np.mean(XW, axis=0)
    muYW = np.mean(YW, axis=0)

    stdXB = np.std(YB, axis=0)
    stdYB = np.std(YB, axis=0)
    stdXW = np.std(XW, axis=0)
    stdYW = np.std(YW, axis=0)

    Bxmin = min(mXB)
    Bxmax = max(mXB)
    Bymin = min(mYB)
    Bymax = max(mYB)
    Wxmin = min(mXW)
    Wxmax = max(mXW)
    Wymin = min(mYW)
    Wymax = max(mYW)

    Bxmin, Bxmax, Bymin, Bymax = correct_box(Bxmin, Bxmax, Bymin, Bymax)
    Wxmin, Wxmax, Wymin, Wymax = correct_box(Wxmin, Wxmax, Wymin, Wymax)

    # area of bboxes
    Barea = abs(Bxmax - Bxmin) * abs(Bymax - Bymin) * im_shape[0] * im_shape[1]
    Warea = abs(Wxmax - Wxmin) * abs(Wymax - Wymin) * im_shape[0] * im_shape[1]

    # store info for Black and White mouse
    frame_dict = {
        'frame_name': im_name,
        'height': im_shape[0],
        'width': im_shape[1],
        'frame_id': im_name,
        'ann_label': keypoint_names,
        'ann': [],
        'ann_B': {'X': XB.tolist(),
                  'Y': YB.tolist(),
                  'bbox': np.array([Bxmin, Bxmax, Bymin, Bymax]).tolist(),
                  'med': np.array([mYB, mXB]).tolist(),
                  'mu': np.array([muYB, muXB]).tolist(),
                  'std': np.array([stdYB, stdXB]).tolist(),
                  'area': Barea.tolist(),
                  },
        'ann_W': {'X': XW.tolist(),
                  'Y': YW.tolist(),
                  'bbox': np.array([Wxmin, Wxmax, Wymin, Wymax]).tolist(),
                  'med': np.array([mYW, mXW]).tolist(),
                  'mu': np.array([muYW, muXW]).tolist(),
                  'std': np.array([stdYW, stdXW]).tolist(),
                  'area': Warea.tolist(),
                  }
                  }
    return frame_dict


def correct_box(xmin, xmax, ymin, ymax, stretch_const=0.04, stretch_factor=0.30, useConstant=True):
    # Code to modify bounding boxes to be a bit larger than the keypoints.

    if useConstant:
        stretch_constx = stretch_const
        stretch_consty = stretch_const
    else:
        stretch_constx = (xmax - xmin) * stretch_factor  # of the width
        stretch_consty = (ymax - ymin) * stretch_factor

    # Calculate the amount to stretch the x by.
    x_stretch = np.minimum(xmin, abs(1 - xmax))
    x_stretch = np.minimum(x_stretch, stretch_constx)

    # Calculate the amount to stretch the y by.
    y_stretch = np.minimum(ymin, abs(1 - ymax))
    y_stretch = np.minimum(y_stretch, stretch_consty)

    # Adjust the bounding box accordingly.
    xmin -= x_stretch
    xmax += x_stretch
    ymin -= y_stretch
    ymax += y_stretch
    return xmin,xmax,ymin,ymax


def geometric_median(X, eps=1e-1):
    # This algorithm for the geometric median comes from Vardi and Zhang 1999, as implemented by orlp on Stack Overflow
    # (https://stackoverflow.com/questions/30299267/geometric-median-of-multidimensional-points)

    y = np.mean(X, 0)

    count = 0
    while True:
        count = count + 1
        D = cdist(X, [y])
        nonzeros = (D != 0)[:, 0]

        Dinv = 1 / D[nonzeros]
        Dinvs = np.sum(Dinv)
        W = Dinv / Dinvs
        T = np.sum(W * X[nonzeros], 0)

        num_zeros = len(X) - np.sum(nonzeros)
        if num_zeros == 0:
            y1 = T
        elif num_zeros == len(X):
            return y
        else:
            R = (T - y) * Dinvs
            r = np.linalg.norm(R)
            rinv = 0 if r == 0 else num_zeros / r
            y1 = max(0, 1 - rinv) * T + min(1, rinv) * y

        if euclidean(y, y1) < eps:
            return y1

        if count > 10:
            return y1

        y = y1